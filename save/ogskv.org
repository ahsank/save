MYPROJECT -*- mode: org -*-




#+begin_src
-std=gnu++17
#end_src


- c1 

builtin_funcs.ini

AddFuncGroup

| Funtion name      | Attr |   |
|-------------------+------+---|
| k2inbuild         |      |   |
| k2inbuildempty    |      |   |
| k2ininsert        |      |   |
| k2inbeginscan     |      |   |
| k2inendscan       |      |   |
| k2inrescan        |      |   |
| k2ingettuple      |      |   |
| k2inbulkdelete    |      |   |
| k2incanreturn     |      |   |
| k2inoptions       |      |   |
| k2incostestimate  |      |   |
| k2invacuumcleanup |      |   |



#+NAME: dependency.cpp
#+BEGIN_SRC cpp
// c1
void doDeletion(obj) {
   /* Deletes single object */
   /* IsK2PgRelationById(object->objectId) before index_drop or heap_drop_with_catalog */
   if (relKind == RELKIND_INDEX || relKind == RELKIND_GLOBAL_INDEX) {
     Relation index = RelationIdGetRelation(object->objectId);
     if (!index->rd_index->indisprimary) {
       K2PgDropIndex(object->objectId);
	   RelationClose(index);
     }
   } else {
      K2PgDropTable(object->objectId);
   }
}
#+END_SRC

#+NAME: template
#+BEGIN_SRC c
// c1
#+END_SRC

#+NAME: genbki.pl
#+BEGIN_SRC perl
# comment toastring
#+END_SRC

#+NAME: src/common/backend/catalog/gs_matview.cpp
#+BEGIN_SRC c
// c1
#+END_SRC

#+NAME: src/common/backend/catalog/heap.cpp
#+BEGIN_SRC c
 // c1, c2
 if (IsK2PgEnabled()) {
   create_storage = relpersistence == RELPERSISTENCE_TEMP;
 }
 if (!IsK2PgRelation(new_rel_desc) && relpersistence == RELPERSISTENCE_UNLOGGED) {
    heap_create_init_fork(new_rel_desc);
 }
#+END_SRC


#+NAME: src/common/backend/catalog/index.cpp
#+BEGIN_SRC c
// c1, c2
static void UpdateIndexRelation() {
  // Duplicate check by get_relname_relid only when !IsK2PgEnabled() || !IsBootstrapProcessingMode()
}
Oid index_create () {
 if (IsK2PgRelation(indexRelation) && !isprimary) {K2PgCreateIndex();}
}
// Delete code of handling RELATION_IS_PARTITIONED

void index_update_stats() {
 BlockNumber relpages =  IsK2PgEnabled() ? 0;
 // skip visibilitymap_count
 // Skip handling of hot chained tuple scan->rs_cblock != root_blkno)
 // Always set  tupleIsAlive = true;
}
double IndexBuildHeapScan() {
// Skip handling HeapTupleIsHeapOnly
// 
}
IndexBuildResult* index_build_storage () {
  // Skip index_build_init_fork
}
void validate_index_heapscan() {
// Use t_self instead of root tuple
}
#+END_SRC

#+NAME: src/common/backend/catalog/indexing.cpp
#+BEGIN_SRC c
// 
void CatalogIndexInsert() {
// Skip for primary key
 ItemPointer t_self = IsK2PgRelation(relationDescs[i]) ? (ItemPointer)(heapTuple->t_k2pgctid) &(
heapTuple->t_self);  

}

/*
 * CatalogIndexDelete - delete index entries for one catalog tuple
 *
 * This should be called for each updated or deleted catalog tuple.
 *
 * This is effectively a cut-down version of ExecDeleteIndexTuples.
 */
static void
CatalogIndexDelete(CatalogIndexState indstate, HeapTuple heapTuple)
{
	numIndexes = indstate->ri_NumIndices;
	relationDescs = indstate->ri_IndexRelationDescs;
	indexInfoArray = indstate->ri_IndexRelationInfo;
	heapRelation = indstate->ri_RelationDesc;

	/* Need a slot to hold the tuple being examined */
	slot = MakeSingleTupleTableSlot(RelationGetDescr(heapRelation));
	ExecStoreTuple(heapTuple, slot, InvalidBuffer, false);

	for (i = 0; i < numIndexes; i++)
	{
		if (IsK2PgEnabled() && relationDescs[i]->rd_index->indisprimary) continue;
        FormIndexDatum(indexInfoArray[i], slot, additinoal);
        ItemPointer t_self = IsK2PgRelation(relationDescs[i]) ? (ItemPointer)(heapTuple->t_k2pgctid) : &(heapTuple->t_self);
        if (IsK2PgRelation(relationDescs[i])) {
            K2PgDeleteIndexRowsByBaseK2Pgctid(relationDescs[i], (Datum)t_self);
        } else {
            index_delete();
        }
	}

	ExecDropSingleTupleTableSlot(slot);
}

void CatalogTupleDelete(Relation heapRel, HeapTuple tup)
{
    if (IsK2PgRelation(heapRel)) {
        K2PgDeleteSysCatalogTuple(heapRel, tup);
		if (K2PgRelHasSecondaryIndices(heapRel)) {
			CatalogIndexState indstate = CatalogOpenIndexes(heapRel);
			CatalogIndexDelete(indstate, tup);
			CatalogCloseIndexes(indstate);
		}
    } else {
        simple_heap_delete(heapRel, &tup->t_self);
    }
}
void CatalogUpdateIndexes(Relation heapRel, HeapTuple heapTuple) {
    indstate = CatalogOpenIndexes(heapRel);
    CatalogIndexInsert(indstate, heapTuple);
	if (IsK2PgEnabled()) {
		has_indices = K2PgRelHasSecondaryIndices(heapRel);
		if (has_indices)
			if (heapTuple->t_k2pgctid)
				CatalogIndexDelete(indstate, heapTuple);
			else
				elog(WARNING, "k2pgctid missing in %s's tuple",
								RelationGetRelationName(heapRel));
		/* Update the local cache automatically */
		K2PgSetSysCacheTuple(heapRel, heapTuple);

		if (has_indices)
			CatalogIndexInsert(indstate, heapTuple);
	    else
        CatalogIndexInsert(indstate, heapTuple);
    }
}

Oid CatalogTupleInsert(Relation heapRel, HeapTuple tup) {
  if (IsK2PgRelation(heapRel)) {
    oid = K2PgExecuteInsert(heapRel, RelationGetDescr(heapRel), tup);
    K2PgSetSysCacheTuple(heapRel, tup);
  } else {
    oid = simple_heap_insert(heapRel, tup);
  }
  return oid;
}

#+END_SRC

Code with c1 or c2 only
1. ==src/common/backend/catalog/pg_collation.cpp==
2. ==src/common/backend/catalog/pg_constraint.cpp==
3. ==src/common/backend/catalog/pg_db_role_setting.cpp==
4. ==src/common/backend/catalog/pg_db_role_setting.cpp==
5. ==src/common/backend/catalog/pg_enum.cpp==
6. ==src/common/backend/catalog/pg_job.cpp==
7. ==src/common/backend/catalog/pg_largeobject.cpp==
8. ==src/common/backend/catalog/pg_object.cpp==
9. ==/src/common/backend/catalog/pg_proc.cpp==
10. ==src/common/backend/catalog/pg_range.cpp b/src/common/backend/catalog/pg_range.cpp==
11. ==src/common/backend/catalog/pg_shdepend.cpp b/src/common/backend/catalog/pg_shdepend.cpp==
12. ==src/common/backend/catalog/pg_type.cpp b/src/common/backend/catalog/pg_type.cpp==
13. ==src/gausskernel/optimizer/commands/comment.cpp==
14. ==src/gausskernel/optimizer/commands/extension.cpp==
15. ==src/gausskernel/optimizer/commands/opclasscmds.cpp==
16. ==src/gausskernel/optimizer/commands/opclasscmds.cpp==
17. ==src/gausskernel/optimizer/commands/opclasscmds.cpp==
18. ==src/gausskernel/optimizer/commands/trigger.cpp==
19. ==src/gausskernel/optimizer/commands/typecmds.cpp==
20. ==src/gausskernel/optimizer/commands/user.cpp==
21. ==src/gausskernel/optimizer/commands/trigger.cpp==
22. ==src/gausskernel/optimizer/commands/typecmds.cpp==
23. ==src/gausskernel/optimizer/commands/user.cpp==
24. ==src/gausskernel/optimizer/rewrite/rewriteRemove.cpp==
25. ==src/gausskernel/optimizer/util/plancat.cpp==
26. ==src/gausskernel/runtime/executor/functions.cpp==

#+BEGIN_SRC c
// c1 and/or c2 or c3
#+END_SRC

#+NAME: /src/common/backend/catalog/pg_proc.cpp
#+BEGIN_SRC c
Datum fmgr_c_validator(PG_FUNCTION_ARGS) {
// Down't validate fdw for libdir/k2_fdw as it's compiled in
}
#+END_SRC

#+NAME: src/common/backend/nodes/copyfuncs.cpp
#+BEGIN_SRC c
static ModifyTable* _copyModifyTable(const ModifyTable* from) {
  COPY_NODE_FIELD(k2PushdownTlist);
}
static Constraint* _copyConstraint(const Constraint* from) {
  COPY_NODE_FIELD(k2pg_index_params);
}
#+END_SRC

#+NAME: src/common/backend/nodes/equalfuncs.cpp
#+BEGIN_SRC c
static bool _equalConstraint(const Constraint* a, const Constraint* b) {
    // As this field is added to Constraint struct
	COMPARE_NODE_FIELD(k2pg_index_params); 
}
#+END_SRC

#+NAME: src/common/backend/nodes/outfuncs.cpp
#+BEGIN_SRC c
static void _outModifyTable(StringInfo str, ModifyTable* node) {
  WRITE_NODE_FIELD(k2PushdownTlist);
}
static void _outConstraint(StringInfo str, Constraint* node) {
  WRITE_NODE_FIELD(k2pg_index_params);
}
#+END_SRC

#+NAME: src/common/backend/parser/gram.y
#+BEGIN_SRC c
// ??
#+END_SRC

#+NAME: src/common/backend/parser/parse_relation.cpp
#+BEGIN_SRC c
void markRTEForSelectPriv(ParseState* pstate, RangeTblEntry* rte, int rti, ...) {
// multi user
// Replace FirstLowInvalidHeapAttributeNumber by K2PgGetFirstLowInvalidAttributeNumberFromOid(rte->relid)
}
#+END_SRC

#+NAME: template src/common/backend/utils/adt/dbsize.cpp
#+BEGIN_SRC c
Datum pg_table_size(PG_FUNCTION_ARGS) {
   // multi
   if (IsK2PgRelation(rel)) {
        // k2 table does not provide table size information, return a dummy value here
        size = 1000;
        PG_RETURN_INT64(size);
    }
}
#+END_SRC

#+NAME: src/common/backend/utils/adt/pgstatfuncs.cpp
#+BEGIN_SRC c
// ?? pg_buffercache_pages check if changed in master
#+END_SRC

#+NAME:
#+BEGIN_SRC c src/common/backend/utils/adt/ri_triggers.cpp
typedef struct RI_ConstraintInfo {
 Oid         conindid;             /* (TODO: add this support) index supporting this constraint */
}
static Datum RI_FKey_check(PG_FUNCTION_ARGS) {
  // Skip cache check for k2p
  	/*
	 * Skip foreign key check if referenced row is present in K2PG cache.
	 */
	if (IsK2PgRelation(pk_rel))
	{
		/*
		 * Get the referenced index table.
		 * For primary key index, we need to use the base table relation.
		 */
		Relation idx_rel = RelationIdGetRelation(riinfo.conindid);
		if (idx_rel->rd_index != NULL)
		{
			ref_table_id = idx_rel->rd_index->indisprimary ?
					idx_rel->rd_index->indrelid : riinfo.conindid;
		}

		BuildPgTupleId(
			pk_rel /* Primary table */,
			fk_rel /* Reference table */,
			ref_table_id == pk_rel->rd_id ? pk_rel : idx_rel /* Reference index */,
			&riinfo, new_row, (void **)&tuple_id, &tuple_id_size);
		RelationClose(idx_rel);

		if (tuple_id != NULL && PgGate_ForeignKeyReferenceExists(ref_table_id, tuple_id, tuple_id_size))
		{
			elog(DEBUG1, "Skipping FK check for table %d, k2pgctid %s", ref_table_id, tuple_id);
			heap_close(pk_rel, RowShareLock);
			return PointerGetDatum(NULL);
		}
	}

   if (SPI_finish() != SPI_OK_FINISH) {
        heap_close(pk_rel, RowShareLock);
        ereport(ERROR, (errcode(ERRCODE_SPI_FINISH_FAILURE), errmsg("SPI_finish failed")));
    } else if (IsK2PgRelation(pk_rel) && tuple_id != NULL) {
		PgGate_CacheForeignKeyReference(ref_table_id, tuple_id, tuple_id_size);
		elog(DEBUG1, "Cached foreign key reference: table ID %u, tuple ID %s",
			 ref_table_id, tuple_id);
	}
}

static bool ri_PerformCheck(RI_QueryKey* qkey, SPIPlanPtr qplan, Relation fk_rel) {
  // Skip if IsK2PgRelation(pk_rel)
}

static void BuildPgTupleId(Relation pk_rel, Relation fk_rel, Relation idx_rel,
				const RI_ConstraintInfo *riinfo, HeapTuple tup,
				void **value, int64_t *bytes) {
	Oid db_oid = K2PgGetDatabaseOid(idx_rel);
	Oid table_oid = RelationGetRelid(idx_rel);

	TupleDesc	tupdesc = fk_rel->rd_att;
	bool using_index = idx_rel->rd_index != NULL && !idx_rel->rd_index->indisprimary;

	Bitmapset *pkey = GetFullK2PgTablePrimaryKey(idx_rel);
	const int nattrs = bms_num_members(pkey);
	std::vector<K2PgAttributeDef> attrs;
	uint64_t tuple_id;

	elog(DEBUG1, "riinfo->nkeys = %d, nattrs = %d, using_index = %d", riinfo->nkeys, nattrs, using_index);

	for (int i = 0; i < riinfo->nkeys; i++)
	{
		K2PgAttributeDef k2attr{};
		k2attr.attr_num = using_index ? (i + 1) : riinfo->pk_attnums[i];
		const int fk_attnum = riinfo->fk_attnums[i];
		k2attr.value.type_id = TupleDescAttr(tupdesc, fk_attnum - 1)->atttypid;
		k2attr.value.datum = heap_getattr(tup, fk_attnum, tupdesc, &k2attr.value.is_null);
		elog(DEBUG1, "key: attr_num = %d, type_id = %d, is_null = %d", k2attr.attr_num, k2attr.value.type_id, k2attr.value.is_null);
		attrs.push_back(k2attr);
	}

	if (using_index) {
		K2PgAttributeDef k2attr{};
		k2attr.attr_num = K2PgUniqueIdxKeySuffixAttributeNumber;
		k2attr.value.type_id = BYTEAOID;
		k2attr.value.datum = 0;
		k2attr.value.is_null = true;
		elog(DEBUG1, "K2PgUniqueIdxKey: attr_num = %d, type_id = %d, is_null = %d", k2attr.attr_num, BYTEAOID, k2attr.value.is_null);
	}

	HandleK2PgStatus(PgGate_DmlBuildPgTupleId(db_oid, table_oid, attrs, &tuple_id));
    *value = (void*)tuple_id;
    *bytes = VARSIZE((Datum)tuple_id);
}
#+END_SRC

#+NAME: /src/common/backend/utils/adt/selfuncs.cpp
#+BEGIN_SRC c
/*-------------------------------------------------------------------------
 *
 * Index cost estimation functions
 *
 *-------------------------------------------------------------------------
 */
List *deconstruct_indexquals(IndexPath *path)
{
	List	   *result = NIL;
	IndexOptInfo *index = path->indexinfo;
	ListCell   *lcc,
			   *lci;

	forboth(lcc, path->indexquals, lci, path->indexqualcols)
	{
		RestrictInfo *rinfo = lfirst_node(RestrictInfo, lcc);
		int			indexcol = lfirst_int(lci);
		Expr	   *clause;
		Node	   *leftop,
				   *rightop;
		IndexQualInfo *qinfo;

		clause = rinfo->clause;

		qinfo = (IndexQualInfo *) palloc(sizeof(IndexQualInfo));
		qinfo->rinfo = rinfo;
		qinfo->indexcol = indexcol;

		if (IsA(clause, OpExpr))
		{
			qinfo->clause_op = ((OpExpr *) clause)->opno;
			leftop = get_leftop(clause);
			rightop = get_rightop(clause);
			if (match_index_to_operand(leftop, indexcol, index))
			{
				qinfo->varonleft = true;
				qinfo->other_operand = rightop;
			}
			else
			{
				Assert(match_index_to_operand(rightop, indexcol, index));
				qinfo->varonleft = false;
				qinfo->other_operand = leftop;
			}
		}
		else if (IsA(clause, RowCompareExpr))
		{
			RowCompareExpr *rc = (RowCompareExpr *) clause;

			qinfo->clause_op = linitial_oid(rc->opnos);
			/* Examine only first columns to determine left/right sides */
			if (match_index_to_operand((Node *) linitial(rc->largs),
									   indexcol, index))
			{
				qinfo->varonleft = true;
				qinfo->other_operand = (Node *) rc->rargs;
			}
			else
			{
				Assert(match_index_to_operand((Node *) linitial(rc->rargs),
											  indexcol, index));
				qinfo->varonleft = false;
				qinfo->other_operand = (Node *) rc->largs;
			}
		}
		else if (IsA(clause, ScalarArrayOpExpr))
		{
			ScalarArrayOpExpr *saop = (ScalarArrayOpExpr *) clause;

			qinfo->clause_op = saop->opno;
			/* index column is always on the left in this case */
			Assert(match_index_to_operand((Node *) linitial(saop->args),
										  indexcol, index));
			qinfo->varonleft = true;
			qinfo->other_operand = (Node *) lsecond(saop->args);
		}
		else if (IsA(clause, NullTest))
		{
			qinfo->clause_op = InvalidOid;
			Assert(match_index_to_operand((Node *) ((NullTest *) clause)->arg,
										  indexcol, index));
			qinfo->varonleft = true;
			qinfo->other_operand = NULL;
		}
		else
		{
			elog(ERROR, "unsupported indexqual type: %d",
				 (int) nodeTag(clause));
		}

		result = lappend(result, qinfo);
	}
	return result;
}
#+END_SRC


#+NAME: src/common/backend/utils/cache/catcache.cpp
#+BEGIN_SRC c
// c2
void InitCatCachePhase2(CatCache* cache, bool touch_index)
{
	/*
	 * TODO: This could be enabled if we handle
	 * "primary key as index" so that PG can open the primary indexes by id.
	 */
    if (IsK2PgEnabled())
	{
		return;
	}

}

static HeapTuple SearchCatCacheMiss(...) {
		/*
		 * Disable negative entries for K2PG to handle case where the entry
		 * was added by (running a command on) another node.
		 * We also don't support tuple update
		 */
		if (IsK2PgEnabled())
		{
			bool allow_negative_entries = cache->id == CASTSOURCETARGET ||
			                              (cache->id == RELNAMENSP &&
			                               DatumGetObjectId(cur_skey[1].sk_argument) ==
			                               PG_CATALOG_NAMESPACE &&
			                               !K2PgIsPreparingTemplates());
			if (!allow_negative_entries)
			{
				return NULL;
			}
		}
}

CatCList* SearchCatCacheList(CatCache* cache, int nkeys, Datum v1, Datum v2, Dat, ...) {
				if (IsK2PgEnabled())
					continue; /* Cannot rely on ctid comparison in K2PG mode */
}

static CatCTup* CatalogCacheCreateEntry() {
       if (IsK2PgEnabled()) {
            HEAPTUPLE_COPY_K2PGTID(dtp->t_k2pgctid, ct->tuple.t_k2pgctid);
       }
}

/*
 * Utility to add a Tuple entry to the cache only if it does not exist.
 * Used only when IsK2PgEnabled() is true.
 * Currently used in two cases:
 *  1. When initializing the caches (i.e. on backend start).
 *  2. When inserting a new entry to the sys catalog (i.e. on DDL create).
 */
void
SetCatCacheTuple(CatCache *cache, HeapTuple tup, TupleDesc desc)
{
	ScanKeyData key[CATCACHE_MAXKEYS];
	Datum		arguments[CATCACHE_MAXKEYS];
	uint32      hashValue;
	Index       hashIndex;
    Dlelem* dlelem = NULL;
    CatCTup* cTup = NULL;

	/* Make sure we're in an xact, even if this ends up being a cache hit */
	Assert(IsTransactionState());

	/*
	 * Initialize cache if needed.
	 */
	if (cache->cc_tupdesc == NULL)
		CatalogCacheInitializeCache(cache);

	/*
	 * initialize the search key information
	 */
	memcpy(key, cache->cc_skey, sizeof(key));
	for (int i = 0; i < CATCACHE_MAXKEYS; i++)
	{
		if (key[i].sk_attno == InvalidOid)
		{
			key[i].sk_argument = (Datum) 0;
			continue;
		}
		bool is_null;
		key[i].sk_argument     = heap_getattr(tup,
		                                      key[i].sk_attno,
		                                      desc,
		                                      &is_null);
		if (is_null)
			key[i].sk_argument = (Datum) 0;
	}

	/*
	 * find the hash bucket in which to look for the tuple
	 */
	hashValue = CatalogCacheComputeHashValue(cache, cache->cc_nkeys,
											 key[0].sk_argument,
											 key[1].sk_argument,
											 key[2].sk_argument,
											 key[3].sk_argument);
	hashIndex = HASH_INDEX(hashValue, cache->cc_nbuckets);

	/* Initialize local parameter array */
	arguments[0] = key[0].sk_argument;
	arguments[1] = key[1].sk_argument;
	arguments[2] = key[2].sk_argument;
	arguments[3] = key[3].sk_argument;

	/*
	 * scan the hash bucket until we find a match or exhaust our tuples
	 *
	 * Note: it's okay to use dlist_foreach here, even though we modify the
	 * dlist within the loop, because we don't continue the loop afterwards.
	 */
    for (dlelem = DLGetHead(&cache->cc_bucket[hashIndex]); dlelem; dlelem = DLGetSucc(dlelem)) {
        cTup = (CatCTup *) DLE_VAL(dlelem);
 		bool res = false;
        if (cTup->dead || cTup->negative)
            continue; /* ignore dead or negative entries */

		if (cTup->hash_value != hashValue)
			continue;            /* quickly skip entry if wrong hash val */

		/*
		 * see if the cached tuple matches our key.
		 */
		HeapKeyTest(&cTup->tuple, cache->cc_tupdesc, cache->cc_nkeys, key, res);
		if (!res)
			continue;

		/*
		 * We found a match in the cache -- nothing to do.
		 */
		return;
	}

	/*
	 * Tuple was not found in cache, so we should add it.
	 */
	CatalogCacheCreateEntry(cache, tup, arguments, hashValue, hashIndex, false);
}

/*
 * K2PG utility method to set the data for a cache list entry.
 * Used during InitCatCachePhase2 (specifically for the procedure name list
 * and for rewrite rules).
 * Code basically takes the second part of SearchCatCacheList (which sets the
 * data if no entry is found).
 */
void
SetCatCacheList(CatCache *cache,
                int nkeys,
                List *current_list)
{
	ScanKeyData cur_skey[CATCACHE_MAXKEYS];
	Datum		arguments[CATCACHE_MAXKEYS];
	uint32      lHashValue;
	CatCList    *cl = NULL;
    Dlelem* dlelem = NULL;
    CatCTup* cTup = NULL;

	List *volatile ctlist = NULL;
	ListCell      *ctlist_item = NULL;
	int           nmembers;
	HeapTuple     ntp = NULL;
	MemoryContext oldcxt = NULL;
	int           i;

	/*
	 * one-time startup overhead for each cache
	 */
	if (cache->cc_tupdesc == NULL)
		CatalogCacheInitializeCache(cache);

	Assert(nkeys > 0 && nkeys < cache->cc_nkeys);
	memcpy(cur_skey, cache->cc_skey, sizeof(cur_skey));
	HeapTuple tup = (HeapTuple)linitial(current_list);
	for (i = 0; i < nkeys; i++)
	{
		if (cur_skey[i].sk_attno == InvalidOid)
			break;
		bool is_null = false; /* Not needed as this is checked before */
		cur_skey[i].sk_argument = heap_getattr(tup,
		                                       cur_skey[i].sk_attno,
		                                       cache->cc_tupdesc,
		                                       &is_null);
	}
	lHashValue = CatalogCacheComputeHashValue(cache,
											  nkeys,
											  cur_skey[0].sk_argument,
											  cur_skey[1].sk_argument,
											  cur_skey[2].sk_argument,
											  cur_skey[3].sk_argument);

#ifdef CATCACHE_STATS
	cache->cc_lsearches++;
#endif


	/* Initialize local parameter array */
	arguments[0] = cur_skey[0].sk_argument;
	arguments[1] = cur_skey[1].sk_argument;
	arguments[2] = cur_skey[2].sk_argument;
	arguments[3] = cur_skey[3].sk_argument;

	/*
	 * List was not found in cache, so we have to build it by reading the
	 * relation.  For each matching tuple found in the relation, use an
	 * existing cache entry if possible, else build a new one.
	 *
	 * We have to bump the member refcounts temporarily to ensure they won't
	 * get dropped from the cache while loading other members. We use a PG_TRY
	 * block to ensure we can undo those refcounts if we get an error before
	 * we finish constructing the CatCList.
	 */
	ResourceOwnerEnlargeCatCacheListRefs(t_thrd.utils_cxt.CurrentResourceOwner);

	ctlist = NIL;

	PG_TRY();
	{
		Relation relation;
		relation = heap_open(cache->cc_reloid, AccessShareLock);

		ListCell *lc;
		foreach(lc, current_list)
		{
			uint32     hashValue;
			Index      hashIndex;
			bool       found = false;

			ntp = (HeapTuple) lfirst(lc);

			/*
			 * See if there's an entry for this tuple already.
			 */
			hashValue = CatalogCacheComputeTupleHashValue(cache, cache->cc_nkeys, ntp);
			hashIndex = HASH_INDEX(hashValue, cache->cc_nbuckets);

            for (dlelem = DLGetHead(&cache->cc_bucket[hashIndex]); dlelem; dlelem = DLGetSucc(dlelem)) {
                cTup = (CatCTup *) DLE_VAL(dlelem);

				if (cTup->dead || cTup->negative)
					continue;    /* ignore dead and negative entries */

				if (cTup->hash_value != hashValue)
					continue;    /* quickly skip entry if wrong hash val */

				if (IsK2PgEnabled())
					continue; /* Cannot rely on ctid comparison in K2PG mode */

                /* A built-in function is all in pg_proc, in upgrade senario, we skip searching
                 * the builtin functions from builtin function array. In non-upgrade mode, the function
                 * found from heap must exist in builtin array.
                 */
                if (IsProcCache(cache) && IsSystemObjOid(HeapTupleGetOid(&(cTup->tuple))) &&
                    u_sess->attr.attr_common.IsInplaceUpgrade == false) {
                    continue;
                }
                if (IsAttributeCache(cache)) {
                    bool attIsNull = false;
                    Oid attrelid = DatumGetObjectId(SysCacheGetAttr(cache->id, &(cTup->tuple),
                                   Anum_pg_attribute_attrelid, &attIsNull));
                    if (IsSystemObjOid(attrelid) && IsValidCatalogParam(GetCatalogParam(attrelid))) {
                        continue;
                    }
                }

				if (!ItemPointerEquals(&(cTup->tuple.t_self),
									   &(ntp->t_self)))
					continue;    /* not same tuple */

				/*
				 * Found a match, but can't use it if it belongs to another
				 * list already
				 */
				if (cTup->c_list)
					continue;

				found = true;
				break;            /* A-OK */
			}

			if (!found)
			{
				/* We didn't find a usable entry, so make a new one */
				cTup = CatalogCacheCreateEntry(cache,
											 ntp,
											 arguments,
											 hashValue,
											 hashIndex,
											 false);
			}

			/* Careful here: add entry to ctlist, then bump its refcount */
			/* This way leaves state correct if lappend runs out of memory */
			ctlist = lappend(ctlist, cTup);
			cTup->refcount++;
		}

		heap_close(relation, AccessShareLock);

		/*
		 * Now we can build the CatCList entry.  First we need a dummy tuple
		 * containing the key values...
		 */
        oldcxt = MemoryContextSwitchTo(u_sess->cache_mem_cxt);
		nmembers = list_length(ctlist);
		cl       = (CatCList *) palloc(offsetof(CatCList, members) +
									   nmembers * sizeof(CatCTup *));

		/* Extract key values */
		CatCacheCopyKeys(cache->cc_tupdesc, nkeys, cache->cc_keyno,
						 arguments, cl->keys);
		MemoryContextSwitchTo(oldcxt);

		/*
		 * We are now past the last thing that could trigger an elog before we
		 * have finished building the CatCList and remembering it in the
		 * resource owner.  So it's OK to fall out of the PG_TRY, and indeed
		 * we'd better do so before we start marking the members as belonging
		 * to the list.
		 */

	}
	PG_CATCH();
	{
        ReleaseTempCatList(ctlist, cache);
		PG_RE_THROW();
	}
	PG_END_TRY();

	cl->cl_magic   = CL_MAGIC;
	cl->my_cache   = cache;
    DLInitElem(&cl->cache_elem, cl);
	cl->refcount   = 0;            /* for the moment */
	cl->dead       = false;
	cl->ordered    = false;
	cl->nkeys      = nkeys;
	cl->hash_value = lHashValue;
	cl->n_members  = nmembers;

	i = 0;
	foreach(ctlist_item, ctlist)
	{
		cl->members[i++] = cTup = (CatCTup *) lfirst(ctlist_item);
		Assert(cTup->c_list == NULL);
		cTup->c_list = cl;
		/* release the temporary refcount on the member */
		Assert(cTup->refcount > 0);
		cTup->refcount--;
		/* mark list dead if any members already dead */
		if (cTup->dead)
			cl->dead = true;
	}
	Assert(i == nmembers);

    DLAddHead(&cache->cc_lists, &cl->cache_elem);

    /* Finally, bump the list's refcount and return it */
    cl->refcount++;
}

/*
 *	RelationHasCachedLists
 *
 *	Returns true if there is a catalog cache associated with this
 * 	relation which is currently caching at least one list.
 */
bool RelationHasCachedLists(const Relation& relation)
{
    CatCache* ccp = NULL;
	Oid reloid;

    /* sanity checks */
    Assert(RelationIsValid(relation));
    Assert(u_sess->cache_cxt.cache_header != NULL);

	reloid = RelationGetRelid(relation);

    for (ccp = u_sess->cache_cxt.cache_header->ch_caches; ccp; ccp = ccp->cc_next)
	{
		if (ccp->cc_reloid == reloid && !DLIsNIL(&ccp->cc_lists) && DLListLength(&ccp->cc_lists) > 0)
			return true;
	}

	return false;
}
#+END_SRC

#+NAME: src/common/backend/utils/cache/inval.cpp
#+BEGIN_SRC c
void CacheInvalidateRelcache(Relation relation) {
    // from if (relation->rd_rel->relisshared) {
    if (relation->rd_rel && relation->rd_rel->relisshared) {
    } 
}

/*
 *		CallSystemCacheCallbacks
 *
 *		Calls all syscache and relcache invalidation callbacks.
 *		This is useful when the entire cache is being reloaded or
 *		invalidated, rather than a single cache entry.
 */
void
CallSystemCacheCallbacks(void)
{
    int			i;
    for (i = 0; i < u_sess->inval_cxt.syscache_callback_count; i++) {
        struct SYSCACHECALLBACK* ccitem = u_sess->inval_cxt.syscache_callback_list + i;

        (*ccitem->function)(ccitem->arg, ccitem->id, 0);
    }

    for (i = 0; i < u_sess->inval_cxt.relcache_callback_count; i++) {
        struct RELCACHECALLBACK* ccitem = u_sess->inval_cxt.relcache_callback_list + i;

        (*ccitem->function)(ccitem->arg, InvalidOid);
    }

    for (i = 0; i < u_sess->inval_cxt.partcache_callback_count; i++) {
        struct PARTCACHECALLBACK* ccitem = u_sess->inval_cxt.partcache_callback_list + i;

        (*ccitem->function)(ccitem->arg, InvalidOid);
    }
}
#+END_SRC

#+NAME: src/common/backend/utils/cache/plancache.cpp
#+BEGIN_SRC c
int32 get_attavgwidth(Oid relid, AttrNumber attnum, bool ispartition) {

    /* avg width stats are not supported for K2PG tables */
       if (IsK2PgEnabled())
               return 0;
}

static bool ChooseCustomPlan(CachedPlanSource* plansource, ParamListInfo boundParam, ...) {
	/* For single row modify operations, use a custom plan so as to push down
	 * the update to the K2 platform without performing the read. This involves
	 * faking the read results in postgres. However the boundParams needs to be
	 * passed for the creation of the plan and hence we would need to enforce a
	 * custom plan.
	 */
	if (plansource->gplan && list_length(plansource->gplan->stmt_list)) {
		PlannedStmt *pstmt =
			linitial_node(PlannedStmt, plansource->gplan->stmt_list);
		if (K2PgIsSingleRowModify(pstmt)) {
			return true;
		}
	}
}
#+END_SRC

#+NAME: src/common/backend/utils/cache/relcache.cpp
#+BEGIN_SRC c
static void RelationBuildTupleDesc(Relation relation, bool onlyLoadInitDefVal) {
  // Check constr->generatedCols before new
}
static void RelationInitPhysicalAddr(Relation relation) {
	if (!IsBootstrapProcessingMode() && IsK2PgRelation(relation)) {
	  return;
}
static OpClassCacheEnt* LookupOpclassInfo(Oid operatorClassOid, StrategyNumber n, ...) {
   // when k2
   indexOK = u_sess->relcache_cxt.criticalRelcachesBuilt;
}
// Initialize relation->rd_pkindex = InvalidOid; following two
void AtEOXact_RelationCache(bool isCommit) {}
void AtEOSubXact_RelationCache(bool isCommit, SubTransactionId mySubid, SubTrans, ...) {}
/* Skip when k2, We do not use a relation map file in K2PG mode yet */ 
void RelationCacheInitializePhase2(void) {}
void RelationCacheInitializePhase3(void) {}
void RelationCacheInitializePhase3(void) {
	 /* In K2PG mode initialize the relache at the beginning so that we need
	 * fewer cache lookups in steady state.
	 */
	if (needNewCacheFile && IsK2PgEnabled())
	{
		K2PgPreloadRelCache();
	}
	/*
	 * During initdb also preload catalog caches (not just relation cache) as
	 * they will be used heavily.
	 */
	if (IsK2PgEnabled() && K2PgIsPreparingTemplates())
	{
		K2PgPreloadCatalogCaches();
	}
}
static void load_critical_index(Oid indexoid, Oid heapoid) {
	if (IsK2PgEnabled()) {
		// We do not support/use critical indexes in K2PG mode yet
		return;
	}
}
List* RelationGetIndexList(Relation relation, bool inc_unused) {
   if (!inc_unused) relation->rd_pkindex = pkeyIndex;
}
void RelationSetIndexList(Relation relation, List* indexIds, Oid oidIndex) {
    /*
    * For the moment, assume the target rel hasn't got a pk or replica
    * index. We'll load them on demand in the API that wraps access to them.
    */
    relation->rd_pkindex = InvalidOid;
}
Bitmapset* RelationGetIndexAttrBitmap(Relation relation, IndexAttrBitmapKind att, ..) {
  indexattrs = bms_add_member(indexattrs, attrnum -  K2PgGetFirstLowInvalidAttributeNumber(relation));
  idindexattrs = bms_add_member(idindexattrs, attrnum - attr_offset);
}
static bool load_relcache_init_file(bool shared) {
  // When k2pg
  rc = snprintf_s(initfilename, sizeof(initfilename), sizeof(initfilename) - 1, "%d_%s", u_sess->proc_cxt.MyDatabaseId, RELCACHE_INIT_FILENAME);
}

static bool load_relcache_init_file(bool shared) {
	if (IsK2PgEnabled()) {
		/* Read the stored catalog version number */
		if (fread(&k2pg_stored_cache_version,
		          1,
		          sizeof(k2pg_stored_cache_version),
		          fp) != sizeof(k2pg_stored_cache_version))
		{
			goto read_failed;
		}

		/*
		 * If we already have a newer cache version (e.g. from reading the
		 * shared init file) then this file is too old.
		 */
		if (k2pg_catalog_cache_version > k2pg_stored_cache_version)
		{
			unlink_initfile(initfilename);
			goto read_failed;
		}

		/* Else, still need to check with the master version to be sure. */
		uint64_t catalog_master_version = 0;
		PgGate_GetCatalogMasterVersion(&catalog_master_version);

		/* File version does not match actual master version (i.e. too old) */
		if (k2pg_stored_cache_version != catalog_master_version)
		{
			unlink_initfile(initfilename);
			goto read_failed;
		}
	}

	if (!IsK2PgEnabled())
	{
        if (shared) {
            if (nailed_rels != NUM_CRITICAL_SHARED_RELS || nailed_indexes != NUM_CRITICAL_SHARED_INDEXES)
                goto read_failed;
        } else {
            if (nailed_rels != NUM_CRITICAL_LOCAL_RELS || nailed_indexes != NUM_CRITICAL_LOCAL_INDEXES)
                goto read_failed;
        }

    }
	if (IsK2PgEnabled())
	{
		/*
		 * Set the catalog version if needed.
		 * The checks above will ensure that if it is already initialized then
		 * we should leave it unchanged (see also comment in pg_k2pg_utils.h).
		 */
		if (k2pg_catalog_cache_version == K2PG_CATCACHE_VERSION_UNINITIALIZED)
		{
			k2pg_catalog_cache_version = k2pg_stored_cache_version;
		}
	}
}

void write_relcache_init_file(bool shared) {
  if (IsK2PgEnabled()) {
    rc = snprintf_s(tempfilename, sizeof(tempfilename), sizeof(tempfilename) - 1, "%d_%s.%d", u_sess->proc_cxt.MyDatabaseId, RELCACHE_INIT_FILENAME, t_thrd.proc_cxt.MyProcPid); securec_check_ss(rc, "\0", "\0");
    rc = snprintf_s(finalfilename, sizeof(finalfilename), sizeof(finalfilename) - 1, "%d_%s", u_sess->proc_cxt.MyDatabaseId, RELCACHE_INIT_FILENAME); securec_check_ss(rc, "\0", "\0");
  }
	if (IsK2PgEnabled()) {
		// Write the psql_catalog_version
		if (fwrite(&k2pg_catalog_cache_version, 1, sizeof(k2pg_catalog_cache_version), fp) != sizeof(k2pg_catalog_cache_version)) {
			elog(FATAL, "could not write init file");
		}
	}
}

void RelationCacheInitFileRemove(void) {
	/*
	 * In K2PG mode we anyway do a cache version check on each backend init
	 * so no need to preemptively clean up the init files here.
	 */
	if (IsK2PgEnabled()) {
		return;
	}
}

/*
 * RelationGetPrimaryKeyIndex -- get OID of the relation's primary key index
 *
 * Returns InvalidOid if there is no such index.
 */
Oid RelationGetPrimaryKeyIndex(Relation relation)
{
	List	   *ilist;

	if (relation->rd_indexvalid == 0)
	{
		/* RelationGetIndexList does the heavy lifting. */
		ilist = RelationGetIndexList(relation);
		list_free(ilist);
		Assert(relation->rd_indexvalid != 0);
	}

	return relation->rd_pkindex;
}

/*
 * A special version of RelationBuildRuleLock (initializes rewrite rules for a relation).
 *
 * Its only difference from the original is that instead of doing a direct scan
 * on RewriteRelationId, it uses partial query against RULERELNAME cache
 * (which we pre-initialized in K2PgPreloadRelCache).
 */
static void
K2PgRelationBuildRuleLock(Relation relation)
{
	MemoryContext rulescxt;
	MemoryContext oldcxt;
	Relation	rewrite_desc;
	TupleDesc	rewrite_tupdesc;
	RuleLock   *rulelock;
	int			numlocks;
	RewriteRule **rules;
	int			maxlocks;

	/*
	 * Make the private context.  Assume it'll not contain much data.
	 */
	rulescxt = AllocSetContextCreate(u_sess->cache_mem_cxt,
									 "relation rules",
									 ALLOCSET_SMALL_SIZES);
	relation->rd_rulescxt = rulescxt;

	/*
	 * allocate an array to hold the rewrite rules (the array is extended if
	 * necessary)
	 */
	maxlocks = 4;
	rules = (RewriteRule **)
		MemoryContextAlloc(rulescxt, sizeof(RewriteRule *) * maxlocks);
	numlocks = 0;

	/*
	 * # ORIGINAL POSTGRES COMMENT:
	 *
	 * open pg_rewrite and begin a scan
	 *
	 * Note: since we scan the rules using RewriteRelRulenameIndexId, we will
	 * be reading the rules in name order, except possibly during
	 * emergency-recovery operations (ie, IgnoreSystemIndexes). This in turn
	 * ensures that rules will be fired in name order.
	 *
	 *
	 *
	 * Instead of full scan, we're doing partial cache lookup. This cache is also using
	 * RewriteRelRulenameIndexId, so the order persists.
	 */
	rewrite_desc = heap_open(RewriteRelationId, AccessShareLock);
	rewrite_tupdesc = RelationGetDescr(rewrite_desc);

	CatCList* rewrite_list = SearchSysCacheList1(RULERELNAME,
												 ObjectIdGetDatum(RelationGetRelid(relation)));

	for (int i = 0; i < rewrite_list->n_members; i++)
	{
		HeapTuple       rewrite_tuple = &rewrite_list->members[i]->tuple;
		Form_pg_rewrite rewrite_form  = (Form_pg_rewrite) GETSTRUCT(rewrite_tuple);

		bool		isnull;
		Datum		rule_datum;
		char		*rule_str;
		RewriteRule *rule;

		rule = (RewriteRule *) MemoryContextAlloc(rulescxt,
												  sizeof(RewriteRule));

		rule->ruleId = HeapTupleGetOid(rewrite_tuple);

		rule->event = (CmdType)(rewrite_form->ev_type - '0');
		rule->enabled = rewrite_form->ev_enabled;
		rule->isInstead = rewrite_form->is_instead;

		/*
		 * Must use heap_getattr to fetch ev_action and ev_qual.  Also, the
		 * rule strings are often large enough to be toasted.  To avoid
		 * leaking memory in the caller's context, do the detoasting here so
		 * we can free the detoasted version.
		 */
		rule_datum = heap_getattr(rewrite_tuple,
								  Anum_pg_rewrite_ev_action,
								  rewrite_tupdesc,
								  &isnull);
		Assert(!isnull);
		rule_str = TextDatumGetCString(rule_datum);
		oldcxt = MemoryContextSwitchTo(rulescxt);
		rule->actions = (List *) stringToNode(rule_str);
		MemoryContextSwitchTo(oldcxt);
		pfree(rule_str);

		rule_datum = heap_getattr(rewrite_tuple,
								  Anum_pg_rewrite_ev_qual,
								  rewrite_tupdesc,
								  &isnull);
		Assert(!isnull);
		rule_str = TextDatumGetCString(rule_datum);
		oldcxt = MemoryContextSwitchTo(rulescxt);
		rule->qual = (Node *) stringToNode(rule_str);
		MemoryContextSwitchTo(oldcxt);
		pfree(rule_str);

		/*
		 * We want the rule's table references to be checked as though by the
		 * table owner, not the user referencing the rule.  Therefore, scan
		 * through the rule's actions and set the checkAsUser field on all
		 * rtable entries.  We have to look at the qual as well, in case it
		 * contains sublinks.
		 *
		 * The reason for doing this when the rule is loaded, rather than when
		 * it is stored, is that otherwise ALTER TABLE OWNER would have to
		 * grovel through stored rules to update checkAsUser fields. Scanning
		 * the rule tree during load is relatively cheap (compared to
		 * constructing it in the first place), so we do it here.
		 */
		setRuleCheckAsUser((Node *) rule->actions, relation->rd_rel->relowner);
		setRuleCheckAsUser(rule->qual, relation->rd_rel->relowner);

		if (numlocks >= maxlocks)
		{
			maxlocks *= 2;
			rules = (RewriteRule **)
				repalloc(rules, sizeof(RewriteRule *) * maxlocks);
		}
		rules[numlocks++] = rule;
	}

	/*
	 * We don't use those preloaded pg_rewrite partial-match lists anywhere else in the code,
	 * so there's no point of keeping them in memory.
	 * We mark them dead so that ReleaseCatCacheList would evict them.
	 */
	rewrite_list->dead = true;
	ReleaseCatCacheList(rewrite_list);
	heap_close(rewrite_desc, AccessShareLock);

	/*
	 * there might not be any rules (if relhasrules is out-of-date)
	 */
	if (numlocks == 0)
	{
		relation->rd_rules = NULL;
		relation->rd_rulescxt = NULL;
		MemoryContextDelete(rulescxt);
		return;
	}

	/*
	 * form a RuleLock and insert into relation
	 */
	rulelock = (RuleLock *) MemoryContextAlloc(rulescxt, sizeof(RuleLock));
	rulelock->numLocks = numlocks;
	rulelock->rules = rules;

	relation->rd_rules = rulelock;
}

struct PgAttrData {
    Form_pg_attribute attp{NULL};
    Datum dval{0};
    bool isNull{false};
};

/*
 * K2PG-mode only utility used to load up the relcache on initialization
 * to minimize the number on K2 queries needed.
 * It is based on (and similar to) RelationBuildDesc but does all relations
 * at once.
 * It works in two steps:
 *  1. Load up all the data pg_class using one full scan iteration. The
 *  relations after this point will all be loaded but incomplete (e.g. no
 *  attribute info set).
 *  2. Load all all the data from pg_attribute using one full scan. Then update
 *  each the corresponding relation once all attributes for it were retrieved.
 *
 *  Note: We assume that any error happening here will fatal so as to not end
 *  up with partial information in the cache.
 */
void K2PgPreloadRelCache()
{
	Relation    relation;
	Oid         relid;
	SysScanDesc scandesc;

	/*
	 * Make sure that the connection is still valid.
	 * - If the name is already dropped from the cache, raise error.
	 * - If the name is still in the cache, we look for the associated OID in the system.
	 *   Raise error if that OID is not MyDatabaseId, which must be either invalid or new DB.
	 */
	Oid dboid = InvalidOid;
	const char *dbname = get_database_name(u_sess->proc_cxt.MyDatabaseId);
	if (dbname != NULL)
	{
		dboid = get_database_oid(dbname, true);
	}
	if (dboid != u_sess->proc_cxt.MyDatabaseId) {
		ereport(FATAL,
						(errcode(ERRCODE_CONNECTION_FAILURE),
						 errmsg("Could not reconnect to database"),
						 errhint("Database might have been dropped by another user")));
	}

    elog(INFO, "K2Pg preloading RelCache for database %d, name %s", dboid, dbname == NULL ? "NULL" : dbname);

	/*
	 * Loading the relation cache requires per-relation lookups to a number of related system tables
	 * to assemble the relation data (e.g. columns, indexes, foreign keys, etc).
	 * This can cause a large number of master queries (since catalog caches are typically not
	 * loaded when calling this).
	 * To handle that we preload the catcaches here for the biggest offenders.
	 *
	 * Note: For historical reasons pg_attribute is currently handled separately below
	 * by querying the entire table once and amending the relevant information into each relation.
	 *
	 * TODO(mihnea, alex): Consider simplifying pg_attribute handling by simply preloading
	 *                     the catcache for that too.
	 */

	K2PgPreloadCatalogCache(INDEXRELID, -1); // pg_index
	K2PgPreloadCatalogCache(RULERELNAME, -1); // pg_rewrite

	/*
	 * 1. Load up the (partial) relation info from pg_class.
	 */
	Relation pg_class_desc = heap_open(RelationRelationId, AccessShareLock);

	scandesc = systable_beginscan(pg_class_desc,
	                              RelationRelationId,
	                              false /* indexOk */,
	                              NULL,
	                              0,
	                              NULL);

	/*
	 * Must copy tuple before releasing buffer.
	 */
	HeapTuple pg_class_tuple;
	while (HeapTupleIsValid(pg_class_tuple = systable_getnext(scandesc)))
	{
		pg_class_tuple = heap_copytuple(pg_class_tuple);

		/*
		 * get information from the pg_class_tuple
		 */
		relid               = HeapTupleGetOid(pg_class_tuple);
		Form_pg_class relp  = (Form_pg_class) GETSTRUCT(pg_class_tuple);

		/*
		 * allocate storage for the relation descriptor, and copy pg_class_tuple
		 * to relation->rd_rel.
		 */
		relation = AllocateRelationDesc(relp);

		/*
		 * initialize the relation's relation id (relation->rd_id)
		 */
		RelationGetRelid(relation) = relid;

		/*
		 * normal relations are not nailed into the cache; nor can a pre-existing
		 * relation be new.  It could be temp though.  (Actually, it could be new
		 * too, but it's okay to forget that fact if forced to flush the entry.)
		 */
		relation->rd_refcnt              = 0;
		relation->rd_isnailed            = false;
		relation->rd_createSubid         = InvalidSubTransactionId;
		relation->rd_newRelfilenodeSubid = InvalidSubTransactionId;
		switch (relation->rd_rel->relpersistence)
		{
			case RELPERSISTENCE_UNLOGGED:
			case RELPERSISTENCE_PERMANENT:
				relation->rd_backend     = InvalidBackendId;
				relation->rd_islocaltemp = false;
				break;
			case RELPERSISTENCE_TEMP:
				if (isTempOrToastNamespace(relation->rd_rel->relnamespace))
				{
					relation->rd_backend     = BackendIdForTempRelations;
					relation->rd_islocaltemp = true;
				}
				else
				{
					/*
					 * If it's a temp table, but not one of ours,
					 * we set rd_backend to the invalid backend id.
					 */
					relation->rd_backend = InvalidBackendId;
					relation->rd_islocaltemp = false;
				}
				break;
			default:
				elog(ERROR,
				     "invalid relpersistence: %c",
				     relation->rd_rel->relpersistence);
				break;
		}

		/*
		 * if it's an index, initialize index-related information
		 */
		if (OidIsValid(relation->rd_rel->relam))
			RelationInitIndexAccessInfo(relation);

		/* extract reloptions if any */
		RelationParseRelOptions(relation, pg_class_tuple);

		/*
		 * initialize the relation lock manager information
		 */
		RelationInitLockInfo(relation); /* see lmgr.c */

		/*
		 * initialize physical addressing information for the relation
		 */
		RelationInitPhysicalAddr(relation);

		/* make sure relation is marked as having no open file yet */
		relation->rd_smgr = NULL;

		/*
		 * now we can free the memory allocated for pg_class_tuple
		 */
		heap_freetuple(pg_class_tuple);

		/*
		 * Insert newly created relation into relcache hash table if needed:
		 * a. If it's not already there (e.g. new table or initialization).
		 * b. If it's a regular (non-system) table it could be changed (e.g. by
		 * an 'ALTER').
		 */
		Relation tmp_rel;
		RelationIdCacheLookup(relation->rd_id, tmp_rel);
		if (!tmp_rel || !IsSystemRelation(tmp_rel))
		{
			RelationCacheInsert(relation);
		}

		/* It's fully valid */
		relation->rd_isvalid = true;
	}

	/* all done */
	systable_endscan(scandesc);

	/*
	 * 2. Iterate over pg_attribute to update the attribute info and the other
	 * missing metadata for the relations above.
	 */

	/* Build table descs */
	TupleConstr *constr;
	AttrDefault *attrdef = NULL;
	Relation	pg_attribute_desc;
	int			need = 0;
	int			ndef = 0;
	HeapTuple	pg_attribute_tuple = NULL;

	relation = NULL;

	/*
	 * Open pg_attribute and begin a scan.  Force heap scan if we haven't yet
	 * built the critical relcache entries (this includes initdb and startup
	 * without a pg_internal.init file).
	 */
	pg_attribute_desc = heap_open(AttributeRelationId, AccessShareLock);

	scandesc = systable_beginscan(pg_attribute_desc,
								  AttributeRelationId,
								  false /* indexOk */,
								  NULL,
								  0,
								  NULL);

	/*
	 * We are scanning through the entire pg_attribute table to get all the attributes (columns)
	 * for all the relations.
	 * When we finish processing a relatin=on's attributes we load up the retrieved
	 * info into the Relation entry, which among other things, sets up then constraint and default
	 * info.
	 */
    std::map<Oid, std::vector<PgAttrData>> rel_to_attrs;
	while (true)
	{
	    pg_attribute_tuple = systable_getnext(scandesc);

		if (!HeapTupleIsValid(pg_attribute_tuple)) {
            break;
		}

        PgAttrData pg_attr_data;
	    pg_attr_data.attp = (Form_pg_attribute) GETSTRUCT(pg_attribute_tuple);
        pg_attr_data.dval = fastgetattr(pg_attribute_tuple, Anum_pg_attribute_attinitdefval, pg_attribute_desc->rd_att, &pg_attr_data.isNull);
        rel_to_attrs[pg_attr_data.attp->attrelid].push_back(pg_attr_data);
    }

    auto it = rel_to_attrs.begin();
    for (; it != rel_to_attrs.end(); ++it) {
        RelationIdCacheLookup(it->first, relation);
        if (!relation) {
            continue;
        }

        /* alter table instantly */
        bool hasInitDefval = false;
        TupInitDefVal* initdvals = NULL;

        need = relation->rd_rel->relnatts;
        ndef = 0;
        attrdef = NULL;
        constr = (TupleConstr*) MemoryContextAlloc(u_sess->cache_mem_cxt, sizeof(TupleConstr));
        constr->generatedCols = NULL;
        constr->has_not_null = false;
        constr->has_generated_stored = false;

        /* set all the *TupInitDefVal* objects later. */
        initdvals = (TupInitDefVal*)MemoryContextAllocZero(u_sess->cache_mem_cxt, need * sizeof(TupInitDefVal));

        for (PgAttrData pg_attr_data : it->second) {
            Form_pg_attribute attp = pg_attr_data.attp;
            Datum dval = pg_attr_data.dval;
            bool isNull = pg_attr_data.isNull;

            /* Skip system attributes */
            if (attp->attnum <= 0)
                continue;

            if (attp->attnum > relation->rd_rel->relnatts)
                elog(ERROR,
                     "invalid attribute number %d for %s",
                     attp->attnum,
                     RelationGetRelationName(relation));

            memcpy(TupleDescAttr(relation->rd_att, attp->attnum - 1), attp, ATTRIBUTE_FIXED_PART_SIZE);

            if (initdvals != NULL) {
                if (isNull) {
                    initdvals[attp->attnum - 1].isNull = true;
                    initdvals[attp->attnum - 1].datum = NULL;
                    initdvals[attp->attnum - 1].dataLen = 0;
                } else {
                    /* fetch and copy the default value. */
                    bytea* val = DatumGetByteaP(dval);
                    int len = VARSIZE(val) - VARHDRSZ;
                    char* buf = (char*)MemoryContextAlloc(u_sess->cache_mem_cxt, len);
                    MemCpy(buf, VARDATA(val), len);

                    initdvals[attp->attnum - 1].isNull = false;
                    initdvals[attp->attnum - 1].datum = (Datum*)buf;
                    initdvals[attp->attnum - 1].dataLen = len;
                    hasInitDefval = true;
                }
            }

            /* Update constraint/default info */
            if (attp->attnotnull)
                constr->has_not_null = true;

            if (attp->atthasdef)
            {
                if (attrdef == NULL)
                    attrdef = (AttrDefault*) MemoryContextAllocZero(u_sess->cache_mem_cxt, relation->rd_rel->relnatts * sizeof(AttrDefault));
                attrdef[ndef].adnum = attp->attnum;
                attrdef[ndef].adbin = NULL;
                ndef++;
            }

            need--;
            if (need == 0)
                break;
        }

        if (need != 0) {
            elog(ERROR, "catalog is missing %d attribute(s) for relid %u",
                 need, RelationGetRelid(relation));
        }

        /*
         * initialize the tuple descriptor (relation->rd_att).
         */
        /* copy some fields from pg_class row to rd_att */
        relation->rd_att->tdtypeid = relation->rd_rel->reltype;
        relation->rd_att->tdtypmod = -1;	/* unnecessary, but... */
        relation->rd_att->tdhasoid = relation->rd_rel->relhasoids;

        /*
        * if this relation doesn't have any alter-table-instantly data,
        * free and reset *initdefvals* to be null.
        */
        if (initdvals != NULL && !hasInitDefval)
            pfree_ext(initdvals);
        else if (initdvals != NULL && relation->rd_att->initdefvals != NULL) {
            for (int i = 0; i < RelationGetNumberOfAttributes(relation); ++i) {
                if (initdvals[i].datum != NULL)
                    pfree_ext(initdvals[i].datum);
            }
            pfree_ext(initdvals);
        } else
            relation->rd_att->initdefvals = initdvals;

        /*
         * The attcacheoff values we read from pg_attribute should all be -1
         * ("unknown").  Verify this if assert checking is on.	They will be
         * computed when and if needed during tuple access.
         *
         * If we are separately loading catalog relcache initial default, their
         * attcacheoff may have been updated. In such case, skip assertation.
         */
#ifdef USE_ASSERT_CHECKING
        {
            int i;

            for (i = 0; i < RelationGetNumberOfAttributes(relation); i++)
                Assert(relation->rd_att->attrs[i]->attcacheoff == -1);
        }
#endif
        /*
         * However, we can easily set the attcacheoff value for the first
         * attribute: it must be zero.  This eliminates the need for special cases
         * for attnum=1 that used to exist in fastgetattr() and index_getattr().
         */
        if (RelationGetNumberOfAttributes(relation) > 0)
            relation->rd_att->attrs[0]->attcacheoff = 0;

        /*
         * Set up constraint/default info
         */
        if (constr->has_not_null || ndef > 0 || relation->rd_rel->relchecks || relation->rd_rel->relhasclusterkey)
        {
            relation->rd_att->constr = constr;

            if (ndef > 0) /* DEFAULTs */
            {
                if (ndef < RelationGetNumberOfAttributes(relation))
                    constr->defval = (AttrDefault *) repalloc(attrdef, ndef * sizeof(AttrDefault));
                else
                    constr->defval = attrdef;

                constr->num_defval = ndef;
                if (!constr->generatedCols) {
                    constr->generatedCols = (char *)MemoryContextAllocZero(u_sess->cache_mem_cxt, RelationGetNumberOfAttributes(relation) * sizeof(char));
                }
                AttrDefaultFetch(relation);
            } else {
                constr->num_defval = 0;
                constr->defval = NULL;
                constr->generatedCols = NULL;
            }

            if (relation->rd_rel->relchecks > 0)    /* CHECKs */
            {
                constr->num_check = relation->rd_rel->relchecks;
                constr->check = (ConstrCheck *) MemoryContextAllocZero(u_sess->cache_mem_cxt, constr->num_check * sizeof(ConstrCheck));
                CheckConstraintFetch(relation);
            } else {
                constr->num_check = 0;
                constr->check = NULL;
            }

            /* Relation has cluster keys */
            if (relation->rd_rel->relhasclusterkey) {
                ClusterConstraintFetch(relation);
            } else {
                constr->clusterKeyNum = 0;
                constr->clusterKeys = NULL;
            }
        }
        else
        {
            pfree(constr);
            relation->rd_att->constr = NULL;
        }

        /*
         * Fetch rules and triggers that affect this relation
         */
        if (relation->rd_rel->relhasrules)
            K2PgRelationBuildRuleLock(relation);
        else
        {
            relation->rd_rules    = NULL;
            relation->rd_rulescxt = NULL;
        }

        if (relation->rd_rel->relhastriggers)
            RelationBuildTriggers(relation);
        else
            relation->trigdesc = NULL;

        // Reset relation.
        relation = NULL;
        need = 0;
	}

	/*
	 * end the scan and close the attribute relation
	 */
	systable_endscan(scandesc);

	heap_close(pg_attribute_desc, AccessShareLock);

	heap_close(pg_class_desc, AccessShareLock);

    u_sess->relcache_cxt.criticalRelcachesBuilt = true;
}
#+END_SRC

#+NAME: src/common/backend/utils/cache/relmapper.cpp
#+BEGIN_SRC c
// Skip following
void RelationMapInvalidate(bool shared);
void RelationMapInvalidateAll(void);
void RelationMapInitializePhase2(void);
void RelationMapInitializePhase3(void);
void perform_relmap_update(bool shared, const RelMapFile* updates);
#+END_SRC

#+NAME: src/common/backend/utils/cache/syscache.cpp
#+BEGIN_SRC c
Bitmapset *
K2PgSysTablePrimaryKey(Oid relid)
{
	Bitmapset *pkey = NULL;

#define K2PgPkAddAttribute(attid) \
	do { pkey = bms_add_member(pkey, attid - FirstLowInvalidHeapAttributeNumber); } while (false)

	switch (relid)
	{
		case AccessMethodOperatorRelationId:
		case AccessMethodProcedureRelationId:
		case AccessMethodRelationId:
		case AggregateRelationId:
		case AttrDefaultRelationId:
		case AuthIdRelationId:
		case CastRelationId:
		case CollationRelationId:
		case ConstraintRelationId:
		case ConversionRelationId:
		case DatabaseRelationId:
		case DefaultAclRelationId:
		case EnumRelationId:
		case ForeignDataWrapperRelationId:
		case ForeignServerRelationId:
		case ForeignTableRelationId:
		case LanguageRelationId:
		case NamespaceRelationId:
		case OperatorClassRelationId:
		case OperatorFamilyRelationId:
		case OperatorRelationId:
		case ProcedureRelationId:
		case RelationRelationId:
		case RewriteRelationId:
		case StatisticExtRelationId:
		case TSConfigRelationId:
		case TSDictionaryRelationId:
		case TSParserRelationId:
		case TSTemplateRelationId:
		case TableSpaceRelationId:
		case TypeRelationId:
		case UserMappingRelationId:
			K2PgPkAddAttribute(ObjectIdAttributeNumber);
			break;
		case AttributeRelationId:
			K2PgPkAddAttribute(Anum_pg_attribute_attrelid);
			K2PgPkAddAttribute(Anum_pg_attribute_attnum);
			break;
		case AuthMemRelationId:
			K2PgPkAddAttribute(Anum_pg_auth_members_roleid);
			K2PgPkAddAttribute(Anum_pg_auth_members_member);
			break;
		case IndexRelationId:
			K2PgPkAddAttribute(Anum_pg_index_indexrelid);
			break;
		case RangeRelationId:
			K2PgPkAddAttribute(Anum_pg_range_rngtypid);
			break;
		case StatisticRelationId:
			K2PgPkAddAttribute(Anum_pg_statistic_starelid);
			break;
		case TSConfigMapRelationId:
			K2PgPkAddAttribute(Anum_pg_ts_config_map_mapcfg);
			K2PgPkAddAttribute(Anum_pg_ts_config_map_maptokentype);
			K2PgPkAddAttribute(Anum_pg_ts_config_map_mapseqno);
			break;
		default: break;
	}

#undef K2PgPkAddAttribute

	return pkey;
}

/*
 * Utility function for K2PG mode. Is used to automatically add entries
 * from common catalog tables to the cache immediately after they are inserted.
 */
void K2PgSetSysCacheTuple(Relation rel, HeapTuple tup)
{
	TupleDesc tupdesc = RelationGetDescr(rel);
	switch (RelationGetRelid(rel))
	{
		case RelationRelationId:
			SetCatCacheTuple(u_sess->syscache_cxt.SysCache[RELOID], tup, tupdesc);
			SetCatCacheTuple(u_sess->syscache_cxt.SysCache[RELNAMENSP], tup, tupdesc);
			break;
		case TypeRelationId:
			SetCatCacheTuple(u_sess->syscache_cxt.SysCache[TYPEOID], tup, tupdesc);
			SetCatCacheTuple(u_sess->syscache_cxt.SysCache[TYPENAMENSP], tup, tupdesc);
			break;
		case ProcedureRelationId:
			SetCatCacheTuple(u_sess->syscache_cxt.SysCache[PROCOID], tup, tupdesc);
			SetCatCacheTuple(u_sess->syscache_cxt.SysCache[PROCNAMEARGSNSP], tup, tupdesc);
			break;
		case AttributeRelationId:
			SetCatCacheTuple(u_sess->syscache_cxt.SysCache[ATTNUM], tup, tupdesc);
			SetCatCacheTuple(u_sess->syscache_cxt.SysCache[ATTNAME], tup, tupdesc);
			break;

		default:
			/* For non-critical tables/indexes nothing to do */
			return;
	}
}

/*
 * In K2PG mode preload the given cache with data from master.
 * If no index cache is associated with the given cache (most of the time), its id should be -1.
 */
void
K2PgPreloadCatalogCache(int cache_id, int idx_cache_id)
{

	CatCache* cache         = u_sess->syscache_cxt.SysCache[cache_id];
	CatCache* idx_cache     = idx_cache_id != -1 ? u_sess->syscache_cxt.SysCache[idx_cache_id] : NULL;
	List*     current_list  = NIL;
	List*     list_of_lists = NIL;
	HeapTuple ntp;
	Relation  relation      = heap_open(cache->cc_reloid, AccessShareLock);
	TupleDesc tupdesc       = RelationGetDescr(relation);

	SysScanDesc scandesc = systable_beginscan(relation,
	                                          cache->cc_indexoid,
	                                          false /* indexOK */,
	                                          NULL /* snapshot */,
	                                          0  /* nkeys */,
	                                          NULL /* key */);

	while (HeapTupleIsValid(ntp = systable_getnext(scandesc)))
	{
		SetCatCacheTuple(cache, ntp, RelationGetDescr(relation));
		if (idx_cache)
			SetCatCacheTuple(idx_cache, ntp, RelationGetDescr(relation));

		/*
		 * Special handling for the common case of looking up
		 * functions (procedures) by name (i.e. partial key).
		 * We set up the partial cache list for function by-name
		 * lookup on initialization to avoid scanning the large
		 * pg_proc table each time.
		 */
		if (cache_id == PROCOID)
		{
			ListCell *lc;
			bool     found_match = false;
			bool     is_null     = false;
			ScanKeyData key      = idx_cache->cc_skey[0];

			Datum ndt = heap_getattr(ntp, key.sk_attno, tupdesc, &is_null);

			if (is_null)
			{
				elog(WARNING,"Ignoring unexpected null "
				                "entry while initializing proc "
				                "cache list");
				continue;
			}

			char *fname          = NameStr(*DatumGetName(ndt));
			char *internal_fname = TextDatumGetCString(heap_getattr(ntp,
			                                                        Anum_pg_proc_prosrc,
			                                                        tupdesc,
			                                                        &is_null));

			/*
			 * The internal name must be unique so if this is the
			 * same as the function name, then this must be the only
			 * or at least first occurrence of this function name.
			 * TODO this assumption holds for standard procs (i.e.
			 * initdb) but we should clean this up when enabling
			 * CREATE PROCEDURE.
			 */
			bool is_canonical = strcmp(fname, internal_fname) == 0;

			if (!is_canonical)
			{
				/*
				 * Look for an existing list for functions with
				 * this name.
				 */
				foreach(lc, list_of_lists)
				{
					List      *fnlist = (List *)lfirst(lc);
					HeapTuple otp     = (HeapTuple) linitial(fnlist);
					Datum     odt     = heap_getattr(otp,
					                                 key.sk_attno,
					                                 tupdesc,
					                                 &is_null);

					Datum test = FunctionCall2Coll(&key.sk_func,
					                               key.sk_collation,
					                               ndt,
					                               odt);
					found_match = DatumGetBool(test);
					if (found_match)
					{
						fnlist = lappend(fnlist, ntp);
						lc->data.ptr_value = fnlist;
						break;
					}
				}
			}
			if (!found_match)
			{
				List *new_list = lappend(NIL, ntp);
				list_of_lists = lappend(list_of_lists, new_list);
			}
		}

		/*
		 * Special handling for pg_rewrite: preload rules list by relation oid.
		 * Note that rules should be ordered by name - which is achieved using
		 * RewriteRelRulenameIndexId index.
		 */
		if (cache_id == RULERELNAME)
		{
			if (!current_list)
			{
				current_list = list_make1(ntp);
			}
			else
			{
				HeapTuple       ltp        = (HeapTuple) llast(current_list);
				Form_pg_rewrite ltp_struct = (Form_pg_rewrite) GETSTRUCT(ltp);
				Form_pg_rewrite ntp_struct = (Form_pg_rewrite) GETSTRUCT(ntp);
				if (ntp_struct->ev_class == ltp_struct->ev_class)
				{
					// This rule is for the same table as the last one, continuing the list
					current_list  = lappend(current_list, ntp);
				}
				else
				{
					// This rule is for another table, changing current list
					list_of_lists = lappend(list_of_lists, current_list);
					current_list  = list_make1(ntp);
				}
			}
		}
	}

	if (current_list)
	{
		list_of_lists = lappend(list_of_lists, current_list);
	}

	systable_endscan(scandesc);

	heap_close(relation, AccessShareLock);

	/* Load up the lists computed above - if any - into the catalog cache. */
	ListCell *lc;
	foreach (lc, list_of_lists)
	{
		List *current_list = (List *) lfirst(lc);
		if (cache_id == PROCOID)
		{
			SetCatCacheList(idx_cache, 1, current_list);
		}
		if (cache_id == RULERELNAME)
		{
			SetCatCacheList(cache, 1, current_list);
		}
	}
	list_free_deep(list_of_lists);
}

/*
 * In K2PG mode load up the caches with data from some essential tables
 * that are looked up often during regular usage.
 *
 * Used during initdb.
 */
static void
K2PgPreloadCatalogCacheIfEssential(int cache_id)
{
	int idx_cache_id = -1;

	switch (cache_id)
	{
		case RELOID:
			idx_cache_id = RELNAMENSP;
			break;
		case TYPEOID:
			idx_cache_id = TYPENAMENSP;
			break;
		case ATTNAME:
			idx_cache_id = ATTNUM;
			break;
		case PROCOID:
			idx_cache_id = PROCNAMEARGSNSP;
			break;
		case OPEROID:
			idx_cache_id = OPERNAMENSP;
			break;
		case CASTSOURCETARGET:
			/* No index cache */
			break;
		default:
			/* non-essential table -- nothing to do */
			return;
	}

	K2PgPreloadCatalogCache(cache_id, idx_cache_id);
}

/*
 * Preload catalog caches with data from the master to avoid master lookups
 * later.
 *
 * Used during initdb.
 */
void
K2PgPreloadCatalogCaches(void)
{
	int			cacheId;

	Assert(CacheInitialized);

	/* Ensure individual caches are initialized */
	InitCatalogCachePhase2();

	for (cacheId = 0; cacheId < SysCacheSize; cacheId++)
		K2PgPreloadCatalogCacheIfEssential(cacheId);
}

#+END_SRC

#+NAME: src/common/backend/utils/error/be_module.cpp
#+BEGIN_SRC c
const module_data module_map[] = {{MOD_K2, "K2"},}
#+END_SRC

#+NAME: src/common/backend/utils/error/elog.cpp
#+BEGIN_SRC c
if (++t_thrd.log_cxt.errordata_stack_depth >= ERRORDATA_STACK_SIZE && elevel >= ERROR );
#+END_SRC

#+NAME: /src/common/backend/utils/fmgr/fmgr.cpp
#+BEGIN_SRC c
static PGFunction load_plpgsql_function(char* funcname) {
 if (!strcmp(funcname, "k2_fdw_validator")) {
        retval = &k2_fdw_validator;
    } else if (!strcmp(funcname, "k2_fdw_handler")) {
        retval = &k2_fdw_handler;
 }
}

static void fmgr_info_C_lang(Oid functionId, FmgrInfo* finfo, HeapTuple procedure, ...) {
 strcmp(probinstring,  "$libdir/k2_fdw") &&
}
#+END_SRC

#+NAME: src/common/backend/utils/init/globals.cpp
#+BEGIN_SRC c
const uint32 GRAND_VERSION_NUM = 92421; // probably no change
#+END_SRC

#+NAME: src/common/backend/utils/init/postinit.cpp
#+BEGIN_SRC c
// Call K2PgInitSession in some fns
// Skip 
 void PostgresInitializer::SetDatabasePath() 
#+END_SRC

#+NAME: src/common/backend/utils/mmgr/mcxt.cpp
#+BEGIN_SRC c
MemoryContext GetThreadLocalCurrentMemoryContext()
{
	return (MemoryContext) PgGate_GetThreadLocalCurrentMemoryContext();
}

MemoryContext SetThreadLocalCurrentMemoryContext(MemoryContext memctx)
{
	return (MemoryContext) PgGate_SetThreadLocalCurrentMemoryContext(memctx);
}

void PrepareThreadLocalCurrentMemoryContext()
{
	if (PgGate_GetThreadLocalCurrentMemoryContext() == NULL)
	{
		MemoryContext memctx = AllocSetContextCreate((MemoryContext) NULL,
		                                             "K2PGExprMemoryContext",
		                                             ALLOCSET_SMALL_SIZES);
		PgGate_SetThreadLocalCurrentMemoryContext(memctx);
	}
}

void ResetThreadLocalCurrentMemoryContext()
{
	MemoryContext memctx = (MemoryContext) PgGate_GetThreadLocalCurrentMemoryContext();
	PgGate_ResetCurrentMemCtxThreadLocalVars();
	MemoryContextReset(memctx);
}

*
 * You should not do memory allocations within a critical section, because
 * an out-of-memory error will be escalated to a PANIC. To enforce that
 * rule, the allocation functions Assert that.
 */
#define AssertNotInCriticalSection(context) \
	Assert(CritSectionCount == 0 || (context)->allowInCritSection)

void MemoryContextReset(MemoryContext context) {
	/*
	 * Reset K2PG context also.
	 */
	if (context->k2pg_memctx != NULL) {
		HandleK2PgStatus(PgGate_ResetMemctx(context->k2pg_memctx));
	}
}

void MemoryContextDelete(MemoryContext context) {
	/*
	 * Destroy K2PG memory context.
	 */
    if (context->k2pg_memctx != NULL) {
	    HandleK2PgStatus(PgGate_DestroyMemctx(context->k2pg_memctx));
	    context->k2pg_memctx = NULL;
    }
}

void *palloc(Size size)
{
	/* duplicates MemoryContextAlloc to avoid increased overhead */
	void	   *ret;
	MemoryContext context = GetCurrentMemoryContext();

	AssertArg(MemoryContextIsValid(context));
	AssertNotInCriticalSection(context);

	if (!AllocSizeIsValid(size))
		elog(ERROR, "invalid memory alloc request size %zu", size);

	context->isReset = false;

	ret = context->methods->alloc(context, 0, size, __FILE__, __LINE__);
	if (unlikely(ret == NULL))
	{
		MemoryContextStats(TopMemoryContext);
		ereport(ERROR,
				(errcode(ERRCODE_OUT_OF_MEMORY),
				 errmsg("out of memory"),
				 errdetail("Failed on request of size %zu in memory context \"%s\".",
						   size, context->name)));
	}

//	VALGRIND_MEMPOOL_ALLOC(context, ret, size);

	return ret;
}

/*
 * Get the K2PG current memory context.
 */
K2PgMemctx GetCurrentK2Memctx() {
	MemoryContext context = GetCurrentMemoryContext();
	AssertArg(MemoryContextIsValid(context));
	AssertNotInCriticalSection(context);

	if (context->k2pg_memctx == NULL) {
		// Create the K2PG context if this is the first time it is used.
		context->k2pg_memctx = PgGate_CreateMemctx();
	}

	return context->k2pg_memctx;
}

#+END_SRC

#+NAME: src/common/pl/plpgsql/src/pl_exec.cpp
#+BEGIN_SRC c
// Set tmptup.t_k2pgctid = (Datum) 0; in following fns
Datum plpgsql_exec_function(PLpgSQL_function* func, FunctionCallInfo fcinfo, bool, ...);
void exec_assign_value(PLpgSQL_execstate* estate, PLpgSQL_datum* target, Datum, ...);
void exec_assign_value(PLpgSQL_execstate* estate, PLpgSQL_datum* target, Datum, ...);
#+END_SRC

#+NAME: src/gausskernel/bootstrap/bootparse.y
#+BEGIN_SRC y
%token XDECLARE K2DECLARE INDEX ON USING XBUILD INDICES PRIMARY UNIQUE XTOAST // K2 & PRIMARY
%token K2PGCHECKINITDBDONE
Boot_Query :
 | Boot_CheckInitDbDone
Boot_K2Index:
          /* EMPTY */ { $$ = NULL; }
          | K2DECLARE PRIMARY INDEX boot_ident oidspec ON boot_ident USING boot_ident
            LPAREN boot_index_params RPAREN
				{
					IndexStmt *stmt = makeNode(IndexStmt);

					do_start();

					stmt->idxname = $4;
					stmt->relation = makeRangeVar(NULL, $7, -1);
					stmt->accessMethod = $9;
					stmt->tableSpace = NULL;
					stmt->indexParams = $11;
					stmt->options = NIL;
					stmt->whereClause = NULL;
					stmt->excludeOpNames = NIL;
					stmt->idxcomment = NULL;
					stmt->indexOid = $5;
					stmt->oldNode = InvalidOid;
					stmt->unique = true;
					stmt->primary = true;
					stmt->isconstraint = false;
					stmt->deferrable = false;
					stmt->initdeferred = false;
					stmt->concurrent = false;

					do_end();

					$$ = stmt;
				}
Boot_CreateStmt:
  RPAREN Boot_K2Index {

					if (IsK2PgEnabled())
					{
						K2PgCreateSysCatalogTable($2, $3, tupdesc, shared_relation, $13);
					}
  }
Boot_CheckInitDbDone:
      	  K2PGCHECKINITDBDONE
      			{
					if (K2PgIsInitDbAlreadyDone())
						exit(K2PG_INITDB_ALREADY_DONE_EXIT_CODE);
				}
		;
#+END_SRC

#+NAME: src/gausskernel/bootstrap/bootscanner.l
#+BEGIN_SRC l
"k2pg_declare"	{ return(K2DECLARE); } /* For K2PG pkeys */
"k2pg_check_if_initdb_is_already_done" { return(K2PGCHECKINITDBDONE);}
#+END_SRC

#+NAME: src/gausskernel/bootstrap/bootstrap.cpp
#+BEGIN_SRC c
void BootStrapProcessMain(int argc, char* argv[]) {
            /* Connect to K2PG cluster. */
            K2PgInitPostgresBackend("postgres");
            K2PgInitSession("template1");
 
  if (IsK2PgEnabled() && !IsK2PgLocalNodeInitdbMode())
    {
        K2InitPGCluster();


        K2PgCreateDatabase(TemplateDbOid,
                          "template1",
                          InvalidOid,
                          FirstBootstrapObjectId);

        K2PgCommitTxn();
    }
	/* We do not use a relation map file in K2PG mode yet */
	if (!IsK2PgEnabled())
	{
        /*
        * We should now know about all mapped relations, so it's okay to write
        * out the initial relation mapping files.
        */
        RelationMapFinishBootstrap();
    }

  if (IsK2PgEnabled() && !IsK2PgLocalNodeInitdbMode())
    {
        // set initDbDone to be true on K2 SKV
        K2FinishInitDB();

        K2PgCommitTxn();
    }
}

// also c2
#+END_SRC

== K2PgInitPostgresBackend(Job name);== and possibly == K2PgInitPostgresBackend("ActiveSessionCollectMain");== in followings

1. ==src/gausskernel/cbb/instruments/ash/ash.cpp==
2. == K2PgInitPostgresBackend("ActiveSessionCollectMain");==
3. == K2PgInitPostgresBackend("ActiveSessionCollectMain");==
4. == K2PgInitPostgresBackend("ActiveSessionCollectMain");==
5. == K2PgInitPostgresBackend("ActiveSessionCollectMain");==
6. ==src/gausskernel/process/job/job_scheduler.cpp==
7. ==src/gausskernel/process/postmaster/autovacuum.cpp==
8. ==/src/gausskernel/process/postmaster/checkpointer.cpp==, skip.
9. ==src/gausskernel/storage/access/ustore/knl_undolauncher.cpp==


#+NAME: src/gausskernel/optimizer/commands/constraint.cpp
#+BEGIN_SRC c
Datum unique_key_recheck(PG_FUNCTION_ARGS) {
        ItemPointer t_self = IsK2PgRelation(fakeIdxRel) ? (ItemPointer)(new_row->t_k2pgctid) : &(new_row->t_self);
        index_insert(fakeIdxRel, values, isnull, t_self, fakeRel, UNIQUE_CHECK_EXISTING);
}
#+END_SRC

#+NAME: src/gausskernel/optimizer/commands/copy.cpp
#+BEGIN_SRC c
static uint64 CopyFrom(CopyState cstate) {
if (IsK2PgRelation(cstate->rel)
  useHeapMultiInsert = false;  
}
#+END_SRC

#+NAME: src/gausskernel/optimizer/commands/createas.cpp
#+BEGIN_SRC c
static void intorel_receive(TupleTableSlot* slot, DestReceiver* self) {
  if (IsK2PgRelation(myState->rel))
    K2PgExecuteInsert(myState->rel, RelationGetDescr(myState->rel), tuple);
}
#+END_SRC

#+NAME: src/gausskernel/optimizer/commands/dbcommands.cpp
#+BEGIN_SRC c
// also c1
void createdb(const CreatedbStmt* stmt) {
  if (dbname != NULL && (strcmp(dbname, "template0") == 0 || strcmp(dbname, "template1") == 0)) {
        K2PgSetPreparingTemplates();
    }
	if (IsK2PgEnabled())
		K2PgCreateDatabase(dboid, dbname, src_dboid, InvalidOid);
}
void dropdb(const char* dbname, bool missing_ok) {
	if (IsK2PgEnabled())
	{
		K2PgDropDatabase(db_id, dbname);
	}
}
#+END_SRC

#+NAME: src/gausskernel/optimizer/commands/indexcmds.cpp
#+BEGIN_SRC c
Oid DefineIndex(Oid relationId, IndexStmt* stmt, Oid indexRelationId, bool, ...) {
	/* Use fast path create index when in nested DDL.  This is desired
	 * when there would be no concurrency issues (e.g. `CREATE TABLE
	 * ... (... UNIQUE (...))`).  However, there may be cases where it
	 * is unsafe to use the fast path.  For now, just use the fast path
	 * in all cases.
	 */
	if (stmt->concurrent && K2PgGetDdlNestingLevel() != 1)
		stmt->concurrent = false;

	/*
	 * Backfilling unique indexes is currently not supported.  This is desired
	 * when there would be no concurrency issues (e.g. `CREATE TABLE ... (...
	 * UNIQUE (...))`).  However, it is not desired in cases where there could
	 * be concurrency issues (e.g. `CREATE UNIQUE INDEX ...`, `ALTER TABLE ...
	 * ADD UNIQUE (...)`).  For now, just use the fast path in all cases.
	 */
	if (stmt->concurrent && stmt->unique)
		stmt->concurrent = false;

	/*
	 * In K2PG mode, switch index method from "btree" or "hash" to "lsm" depending on whether
	 * the table is stored in K2PG storage or not (such as temporary tables).
	 */
	if (IsK2PgEnabled())
	{
		if (accessMethodName == NULL)
		{
			accessMethodName = const_cast<char*>(IsK2PgRelation(rel) ? DEFAULT_K2PG_INDEX_TYPE : DEFAULT_INDEX_TYPE);
		}
		else if (IsK2PgRelation(rel))
		{
			if (strcmp(accessMethodName, "btree") == 0 || strcmp(accessMethodName, "hash") == 0)
			{
				ereport(NOTICE,
						(errmsg("index method \"%s\" was replaced with \"%s\" in K2PG",
								accessMethodName, DEFAULT_K2PG_INDEX_TYPE)));
				accessMethodName = DEFAULT_K2PG_INDEX_TYPE;
			}
		}
	}
    if (IsK2PgRelation(rel) && accessMethodId != K2INDEX_AM_OID)
      ereport(ERROR,
				(errmsg("index method \"%s\" not supported yet",
						accessMethodName),
				 errhint(" ")));
    K2PgDecrementDdlNestingLevel(true /* success */);
	K2PgIncrementDdlNestingLevel();
    // TODO: need to add index permission API calls once we support that ?
}
void ComputeIndexAttrs(IndexInfo* indexInfo, Oid* typeOidP, Oid* collationOidP, ...) {
  /*
     * Get whether the index will use K2PG ordering
     */
    if (IsK2PgEnabled() &&
        !IsBootstrapProcessingMode() &&
        !K2PgIsPreparingTemplates()) {
        Relation rel = RelationIdGetRelation(relId);
        use_k2pg_ordering = IsK2PgRelation(rel) && !IsSystemRelation(rel);
        RelationClose(rel);
    }
        if (IsK2PgEnabled()) {
            if (use_k2pg_ordering) {
                switch (attribute->ordering) {
                    case SORTBY_ASC:
                    case SORTBY_DESC:
                        range_index = true;
                        break;
                    case SORTBY_DEFAULT:
                        /*
                         * In K2PG mode, first attribute defaults to HASH and
                         * other attributes default to ASC.
                         */
                        if (attn > 0) {
                            range_index = true;
                            break;
                        }
                        if (range_index)
                            ereport(ERROR,
                                    (errcode(ERRCODE_INVALID_OBJECT_DEFINITION),
                                     errmsg("hash column not allowed after an ASC/DESC column")));
                        break;
                    default:
                        ereport(ERROR,
                                (errcode(ERRCODE_INVALID_OBJECT_DEFINITION),
                                 errmsg("unsupported column sort order")));
                        break;
                }
            }
        }

   if (amcanorder) {
            /* default ordering is ASC */
            /*
             * In K2PG, use HASH as the default for the first column of
             * non-colocated tables
             */
            if (use_k2pg_ordering &&
                attn == 0 &&
                attribute->ordering == SORTBY_DEFAULT)
                colOptionP[attn] |= INDOPTION_HASH;

            /* default ordering is ASC
            * TODO
            * We do not support DESC index (see chogori-sql issue #268),
            * so commenting this out forces PG to see the index as ascending and sort if necessary
            * This can be uncommented if the issue is resolved.
            if (attribute->ordering == SORTBY_DESC)
                colOptionP[attn] = ((uint16)colOptionP[attn]) | INDOPTION_DESC;
            */
   }
}
#+END_SRC

#+NAME: src/gausskernel/optimizer/commands/matview.cpp
#+BEGIN_SRC c
ItemPointer t_self = IsK2PgRelation(mapIdx) ? (ItemPointer)(tup->t_k2pgctid) : &(tup->t_self);
// in
void insert_into_matview_map(Oid mapid, Oid matid, ItemPointer matctid, ...);
void insert_into_mlog_table(Relation rel, Oid mlogid, HeapTuple tuple, ItemPoint, ...);
#+END_SRC

#+NAME: src/gausskernel/optimizer/commands/tablecmds.cpp
#+BEGIN_SRC c
Oid DefineRelation(CreateStmt* stmt, char relkind, Oid ownerId, bool isCTAS) {
  CheckIsK2PgSupportedRelationByKind(relkind);
  K2PgCreateTable(stmt, relkind, relisshared, descriptor, relationId, namespaceId);
}
void renameatt(RenameStmt* stmt) {K2PgRename(stmt, relid);}
void RenameRelation(RenameStmt* stmt) {K2PgRename(stmt, relid);}
void AlterTable(Oid relid, LOCKMODE lockmode, AlterTableStmt* stmt) {
//-        ATController(rel, stmt->cmds, interpretInhOption(stmt->relation->inhOpt), lockmode);
//+        ATController(stmt, rel, stmt->cmds, interpretInhOption(stmt->relation->inhOpt), lockmode);

}
static void ATController(AlterTableStmt* stmt, Relation rel, List* cmds, bool recurse, LOCKMODE lockmode) {
  Oid relid = RelationGetRelid(rel);
  /*
   * Prepare the K2PG alter statement handle -- need to call this before the
   * system catalogs are changed below (since it looks up table metadata).
   */
   K2PgStatement handle = NULL;
   if (IsK2PgRelation(rel)) {handle = K2PgPrepareAlterTable(stmt, rel, relid);}
   /*
   * Execute the K2PG alter table (if needed).
   * Must call this after syscatalog updates succeed (e.g. dependencies are
   * checked) since we do not support rollback of K2PG alter operations yet.
   */
   if (handle) {K2PgExecAlterPgTable(handle, relid);}
}

// Remove  bool isDeltaTable
static AlteredTableInfo* ATGetQueueEntry(List** wqueue, Relation rel) {
}
// also c1, c2
#+END_SRC

#+NAME: src/gausskernel/optimizer/commands/trigger.cpp
#+BEGIN_SRC c
ltrmark:
  tuple.t_k2pgctid = (Datum) 0;
#+END_SRC

#+NAME: src/gausskernel/optimizer/path/allpaths.cpp
#+BEGIN_SRC c
RelOptInfo* make_one_rel(PlannerInfo* root, List* joinlist)  {
  if (IsK2PgEnabled()) {
    for (rti = 1; rti < root->simple_rel_array_size; rti) {
      RelOptInfo *relation = root->simple_rel_array[rti];

      if (relation != NULL && relation->rtekind == RTE_RELATION) {
        RangeTblEntry *rte = root->simple_rte_array[rti];
        if (IsK2PgRelationById(rte->relid)) {
          // Set the K2PG FDW routine because we will use the foreign scan API below.
          relation->fdwroutine = (FdwRoutine*)k2_fdw_handler(NULL);
        }
      }
    }
  }
}
void set_rel_size(PlannerInfo* root, RelOptInfo* rel, Index rti, RangeTblEntry*, ...) {
  if (IsK2PgRelationById(rte->relid)) set_foreign_size(root, rel, rte);
}

#+END_SRC

#+NAME: src/gausskernel/optimizer/plan/createplan.cpp
#+BEGIN_SRC c
ModifyTable* make_modifytable(CmdType operation, bool canSetTag, List* resultRel, ...) {
  // TODO: add logic to populate k2PushdownTlist if it is useful
  node->k2PushdownTlist = NULL;
}
#+END_SRC

#+NAME: src/gausskernel/optimizer/rewrite/rewriteHandler.cpp
#+BEGIN_SRC c
static void rewriteTargetListUD(Query* parsetree, RangeTblEntry* target_rte, ...) {
  if (IsK2PgRelation(target_relation))
  {
    /*
    * If there are secondary indices on the target table, or if we have a
    * row-level trigger corresponding to the operations, then also return
    * the whole row.
    */
    if (K2PgRelHasOldRowTriggers(target_relation, parsetree->commandType) ||
    K2PgRelHasSecondaryIndices(target_relation))
    {
      var = makeWholeRowVar(target_rte, parsetree->resultRelation, 0, false);
      attrname = "wholerow";
    }
 
    /*
    * Emit k2pgctid so that executor can find the row to update or delete from K2PG tables.
    */
    var = makeVar(parsetree->resultRelation, K2PgTupleIdAttributeNumber, BYTEAOID, -1, InvalidOid, 0);
    attrname = "k2pgctid";
  }
}
#+END_SRC

#+NAME: src/gausskernel/optimizer/util/plancat.cpp
#+BEGIN_SRC c
void get_relation_info(PlannerInfo* root, Oid relationObjectId, bool inhparent, ...) {
  if (IsK2PgRelation(relation) && (((unsigned int)opt) & INDOPTION_HASH) != 0) {
    info->reverse_sort[i] = false;
    info->nulls_first[i] = false;
  }
  // Skip distributed relation code PGXC for IsK2PgRelation(indexRelation)
}

void estimate_rel_size(Relation rel, int32* attr_widths, RelPageType* pages, ...) {
  /*
  * We don't support forwarding k2 size estimates to postgres yet.
  * Use whatever is in pg_class.
  */
  if (IsK2PgEnabled())
  {
    *pages = rel->rd_rel->relpages;
    *tuples = rel->rd_rel->reltuples;
    *allvisfrac = 0;
    return;
  }

}


#+END_SRC

#+NAME: src/gausskernel/process/postmaster/postmaster.cpp
#+BEGIN_SRC c
int PostmasterMain(int argc, char* argv[]) {
  while ((opt = getopt_r(..., "...:K") != -1) {
    case 'K':
      k2_mode_enabled = true;
      break;
  }
  if (k2_mode_enabled || K2PgIsEnabledInPostgresEnvVar()) {
    g_instance.k2_cxt.isK2ModelEnabled = true;
    u_sess->k2_cxt.isK2ModelEnabled = true;
    ereport(LOG, (errmsg("K2_Mode is ENABLED in PostgreSQL.")));
  } else {
    g_instance.k2_cxt.isK2ModelEnabled = false;
    u_sess->k2_cxt.isK2ModelEnabled = false;
    ereport(LOG, (errmsg("K2_Mode is NOT ENABLED in PostgreSQL.")));
  }
  // Comment g_instance.pid_cxt.ReaperBackendPID = initialize_util_thread(REAPER);
  // if k2 enabled skip
  //   g_instance.pid_cxt.CheckpointerPID = initialize_util_thread(CHECKPOINT_THREAD);
  //   g_instance.pid_cxt.AutoVacPID = initialize_util_thread(AUTOVACUUM_LAUNCHER);
  //   g_instance.pid_cxt.PgJobSchdPID = initialize_util_thread(JOB_SCHEDULER);
  // Bunch of other jobs commented
}
#+END_SRC

#+NAME: src/gausskernel/process/postmaster/twophasecleaner.cpp
#+BEGIN_SRC c
// connect_timeout from 5 to 60
#+END_SRC

#+NAME: src/gausskernel/process/tcop/postgres.cpp
#+BEGIN_SRC c
void quickdie(SIGNAL_ARGS) {
  if (IsK2PgEnabled()) {K2PgOnPostgresBackendShutdown();}
}

int PostgresMain(int argc, char* argv[], const char* dbname, const char* username) {
  for (int i = 0; i < argc; i++) {
    if (strcmp(argv[i], "template0") == 0 || strcmp(argv[i], "template1") == 0) {
      K2PgSetPreparingTemplates();
    }
  }
  if (dbname) {
    if (strcmp(dbname, "template0") == 0 || strcmp(dbname, "template1") == 0) {
      K2PgSetPreparingTemplates();
    }
    } else if (username) {
        if (strcmp(username, "template0") == 0 || strcmp(username, "template1") == 0) {
            K2PgSetPreparingTemplates();
        }
    }
    /* Connect to K2PG cluster. */
    K2PgInitPostgresBackend("PostgresMain");
    K2PgInitSession(dbname);
    if (IsK2PgEnabled() && k2pg_need_cache_refresh)
    {
      K2PgRefreshCache();
    }

    if (IsK2PgEnabled()) {
      K2PgCheckSharedCatalogCacheVersion();
    }
    // Add  PG_TRY(); around exec_simple_query

    PG_TRY();
    {
      exec_simple_query(query_string, QUERY_MESSAGE, &input_message); 
/* @hdfs Add the second parameter */
    }
    PG_CATCH();
    {
      bool need_retry = false;
      MemoryContext oldcontext = GetCurrentMemoryContext();
      K2PgPrepareCacheRefreshIfNeeded(oldcontext,
      k2pg_check_retry_allowed(query_string),
      &need_retry);
      if (need_retry) {
        elog(WARNING, "Retry query is not supported yet for query: %s", query_string);
      }
      PG_RE_THROW();
    }
    PG_END_TRY();
                

    PG_TRY();
    {
      statement_init_metric_context();
      exec_parse_message(query_string, stmt_name, paramTypes, paramTypeNames, numParams);
      statement_commit_metirc_context();
    }
    PG_CATCH();
    {
      /*
      * Cannot retry parse statements yet and have to abort the followup bind/execute.
      */
      bool need_retry = false;
      MemoryContext oldcontext = GetCurrentMemoryContext();
      K2PgPrepareCacheRefreshIfNeeded(oldcontext,
        false /* consider_retry */,
        &need_retry);
        PG_RE_THROW();
      }
      PG_END_TRY();
 

      PG_TRY();
      {
        exec_execute_message(portal_name, max_rows);
      }
      PG_CATCH();
      {
      bool can_retry = IsK2PgEnabled() &&
        u_sess->pcache_cxt.unnamed_stmt_psrc &&
        k2pg_check_retry_allowed(u_sess->pcache_cxt.unnamed_stmt_psrc->query_string);

        bool need_retry = false;
        MemoryContext oldcontext = GetCurrentMemoryContext();
        K2PgPrepareCacheRefreshIfNeeded(oldcontext,
          can_retry,
          &need_retry);
          if (need_retry) {
          elog(WARNING, "Retry execution is not supported yet for %s", portal_name);
          }
          PG_RE_THROW();
          }
        PG_END_TRY();

}

#+END_SRC

#+NAME: postgress.cpp 2
#+BEGIN_SRC c
/*
 * Reload the postgres caches and update the cache version.
 * Note: if catalog changes sneaked in since getting the
 * version it is unfortunate but ok. The master version will have
 * changed too (making our version number obsolete) so we will just end
 * up needing to do another cache refresh later.
 * See the comment for k2pg_catalog_cache_version in 'pg_k2pg_utils.c' for
 * more details.
 */
static void K2PgRefreshCache()
{

       /*
        * Check that we are not already inside a transaction or we might end up
        * leaking cache references for any open relations (i.e. relations in-use by
        * the current transaction).
        *
        * Caller(s) should have already ensured that this is the case.
        */
       if (t_thrd.postgres_cxt.xact_started)
       {
               ereport(ERROR,
                       (errcode(ERRCODE_INTERNAL_ERROR),
                                       errmsg("Cannot refresh cache within a transaction")));
       }

    elog(INFO, "K2Pg refreshing cache ...");


       /* Get the latest syscatalog version from the master */
       uint64_t catalog_master_version = 0;
       PgGate_GetCatalogMasterVersion(&catalog_master_version);

       /* Need to execute some (read) queries internally so start a local txn. */
       start_xact_command();

       /* Clear and reload system catalog caches, including all callbacks. */
       ResetCatalogCaches();
       CallSystemCacheCallbacks();
       K2PgPreloadRelCache();

       /* Also invalidate the pggate cache. */
       PgGate_InvalidateCache();

       /* Set the new ysql cache version. */
       k2pg_catalog_cache_version = catalog_master_version;
       k2pg_need_cache_refresh = false;

       finish_xact_command();
}

static void K2PgPrepareCacheRefreshIfNeeded(MemoryContext oldcontext,
                                          bool consider_retry,
                                          bool *need_retry)
{
       bool            need_global_cache_refresh = false;
       bool            need_table_cache_refresh = false;
       char       *table_to_refresh = NULL;
       const char *table_cache_refresh_search_str = "schema version mismatch for table ";

       *need_retry = false;

       /*
        * A retry is only required if the transaction is handled by K2PG.
        */
       if (!IsK2PgEnabled() || t_thrd.log_cxt.errordata_stack_depth < 0)
               return;

    elog(DEBUG5, "K2PgPrepareCacheRefreshIfNeeded is called");

       /* Get error data */
       ErrorData *edata = NULL;
       MemoryContextSwitchTo(oldcontext);
       edata = CopyErrorData();

       bool is_retryable_err = K2PgNeedRetryAfterCacheRefresh(edata);
       if ((table_to_refresh = strstr(edata->message,
                                                                  table_cache_refresh_search_str)) != NULL)

       {
               size_t size_of_uuid = 16; /* boost::uuids::uuid::static_size() */
               size_t size_of_hex_uuid = size_of_uuid * 2;

               /* Skip to the table id part of the error message. */
               table_to_refresh = strlen(table_cache_refresh_search_str);
               if (strlen(table_to_refresh) < size_of_hex_uuid)
                       /* Unexpected table id size; ignore table cache refreshing. */
                       table_to_refresh = NULL;
               else
               {
                       /* Trim off the rest of the message. */
                       *(table_to_refresh  size_of_hex_uuid) = '\0';
                       /* Duplicate the string to safely FreeErrorData below. */
                       table_to_refresh = pstrdup(table_to_refresh);
               }
       }
       need_table_cache_refresh = table_to_refresh != NULL;


       /*
        * Get the latest syscatalog version from the master to check if we need
        * to refresh the cache.
        */
       uint64_t catalog_master_version = 0;
       PgGate_GetCatalogMasterVersion(&catalog_master_version);
       need_global_cache_refresh =
               k2pg_catalog_cache_version != catalog_master_version;
       if (!(need_global_cache_refresh || need_table_cache_refresh))
               return;

       /*
        * Reset catalog version so that the cache gets marked as invalid and
        * will be refreshed after the txn ends.
        */
       if (need_global_cache_refresh)
               k2pg_need_cache_refresh = true;

       /*
        * Prepare to retry the query if possible.
        */
       if (is_retryable_err)
       {
               /*
                * For single-query transactions we abort the current
                * transaction to undo any already-applied operations
                * and retry the query.
                *
                * For transaction blocks we would have to re-apply
                * all previous queries and also continue the
                * transaction for future queries (before commit).
                * So we just re-throw the error in that case.
                *
                */
               if (consider_retry && !IsTransactionBlock())
               {
                       /* Clear error state */
                       FlushErrorState();
                       FreeErrorData(edata);

                       /* Abort the transaction and clean up. */
                       AbortCurrentTransaction();
//                     if (AM_WAL_SENDER)
//                             WalSndErrorCleanup();

//                     if (MyReplicationSlot != NULL)
//                             ReplicationSlotRelease();

//                     ReplicationSlotCleanup();

                       if (u_sess->postgres_cxt.doing_extended_query_message)
                               u_sess->postgres_cxt.ignore_till_sync = true;

                       t_thrd.postgres_cxt.xact_started = false;

                       /* Refresh cache now so that the retry uses latest version. */
                       if (need_global_cache_refresh)
                               K2PgRefreshCache();
                       else
                       {
                               /* need_table_cache_refresh */
                               ereport(LOG,
                                               (errmsg("invalidating table cache entry %s",
                                                               table_to_refresh)));
                               HandleK2PgStatus(PgGate_InvalidateTableCacheByTableId(table_to_refresh));
                       }

                       *need_retry = true;
               }
                       *need_retry = true;
               }
               else
               {
                       if (need_global_cache_refresh)
                               ereport(ERROR,
                                               (errcode(ERRCODE_INTERNAL_ERROR),
                                                errmsg("Catalog Version Mismatch: A DDL occurred "
                                                               "while processing this query. Try Again.")));
                       else
                       {
                               /* need_table_cache_refresh */
                               ereport(ERROR,
                                               (errcode(ERRCODE_INTERNAL_ERROR),
                                                errmsg("%s", edata->message)));
                       }
               }
       }
       else
       {
               /* Clear error state */
               FlushErrorState();
               FreeErrorData(edata);
       }
}
/*
 * Parse query tree via pg_parse_query, suppressing log messages below ERROR level.
 * This is useful e.g. for avoiding "not supported yet and will be ignored" warnings.
 */
static List* k2pg_parse_query_silently(const char *query_string)
{
       List* parsetree_list;

       int prev_log_min_messages    = log_min_messages;
       int prev_client_min_messages = client_min_messages;
       PG_TRY();
       {
               log_min_messages    = ERROR;
               client_min_messages = ERROR;
               parsetree_list      = pg_parse_query(query_string);
               log_min_messages    = prev_log_min_messages;
               client_min_messages = prev_client_min_messages;
       }
       PG_CATCH();
       {
               log_min_messages    = prev_log_min_messages;
               client_min_messages = prev_client_min_messages;
               PG_RE_THROW();
       }
       PG_END_TRY();

       return parsetree_list;
}

/*
 * Parse query tree via pg_parse_query, suppressing log messages below ERROR level.
 * This is useful e.g. for avoiding "not supported yet and will be ignored" warnings.
 */
static List* k2pg_parse_query_silently(const char *query_string)
{
       List* parsetree_list;

       int prev_log_min_messages    = log_min_messages;
       int prev_client_min_messages = client_min_messages;
       PG_TRY();
       {
               log_min_messages    = ERROR;
               client_min_messages = ERROR;
               parsetree_list      = pg_parse_query(query_string);
               log_min_messages    = prev_log_min_messages;
               client_min_messages = prev_client_min_messages;
       }
       PG_CATCH();
       {
               log_min_messages    = prev_log_min_messages;
               client_min_messages = prev_client_min_messages;
               PG_RE_THROW();
       }
       PG_END_TRY();

       return parsetree_list;
}

static const char* k2pg_parse_command_tag(const char *query_string)
{
       List* parsetree_list = k2pg_parse_query_silently(query_string);

       if (list_length(parsetree_list) > 0) {
        Node* raw_parse_tree = (Node*)linitial(parsetree_list);
        return CreateCommandTag(raw_parse_tree);
       } else {
               return NULL;
       }
}

/*
 * Only retry SELECT, INSERT, UPDATE and DELETE commands.
 * Do the minimum parsing to find out what the command is
 */
static bool k2pg_check_retry_allowed(const char *query_string)
{
       if (!query_string)
               return false;

       const char* command_tag = k2pg_parse_command_tag(query_string);
       if (!command_tag)
               return false;

       return (strncmp(command_tag, "DELETE", 6) == 0 ||
               strncmp(command_tag, "INSERT", 6) == 0 ||
               strncmp(command_tag, "SELECT", 6) == 0 ||
               strncmp(command_tag, "UPDATE", 6) == 0);
}


static void K2PgCheckSharedCatalogCacheVersion() {
       /*
        * We cannot refresh the cache if we are already inside a transaction, so don't
        * bother checking shared memory.
        */
       if (t_thrd.postgres_cxt.xact_started)
               return;

       /*
        * Don't check shared memory if we are in initdb. E.g. during initial system
        * catalog snapshot creation, tablet servers may not be running.
        */
       if (K2PgIsInitDbModeEnvVarSet())
               return;

       uint64_t shared_catalog_version;
       HandleK2PgStatus(PgGate_GetSharedCatalogVersion(&shared_catalog_version));

       if (k2pg_catalog_cache_version < shared_catalog_version) {
               K2PgRefreshCache();
       }
}


#+END_SRC

#+NAME: src/gausskernel/process/tcop/utility.cpp
#+BEGIN_SRC c
void CreateCommand(CreateStmt *parse_tree, const char *query_string, ParamListIn, ...) {
  /* No need for toasting attributes in K2PG mode */
}
oid standard_ProcessUtility(Node* parse_tree, const char* query_string, ...) {
               case TRANS_STMT_PREPARE:
  if(IsK2PgEnabled()) {
    ereport(ERROR,
      (errcode(ERRCODE_FEATURE_NOT_SUPPORTED),
      errmsg("PREPARE not supported by K2PG yet")));
  }
 
}
#+END_SRC

#+NAME: src/gausskernel/runtime/executor/execMain.cpp
#+BEGIN_SRC c
void ExecConstraints(ResultRelInfo *resultRelInfo, TupleTableSlot *slot,...) {
  // Comment following
  // Form_pg_attribute att = TupleDescAttr(tupdesc, attrChk - 1);

  // if (mtstate && mtstate->k2pg_mt_is_single_row_update_or_delete &&
  //     !bms_is_member(att->attnum - K2PgGetFirstLowInvalidAttributeNumber(rel), modifiedCols))
  // {
  //      /*
  //       * For single-row-updates, we only know the values of the
  //       * modified columns. But in this case it is safe to skip the
  //       * unmodified columns anyway.
  //       */
  //      continue;
  // }

}
#+END_SRC

#+NAME: src/gausskernel/runtime/executor/execScan.cpp
#+BEGIN_SRC c
TupleTableSlot* ExecScan(ScanState* node, ExecScanAccessMtd access_mtd, ...) {
  if (IsK2PgEnabled()) {
    if (slot->tts_tuple != NULL) {
      // assign tts_k2pgctid for slot
      HEAPTUPLE_COPY_K2PGTID(((HeapTuple)(slot->tts_tuple))->t_k2pgctid, slot->tts_k2pgctid);
    }
  }

  if (IsK2PgEnabled()) {
    if (slot->tts_k2pgctid != 0) {
      HEAPTUPLE_COPY_K2PGTID(slot->tts_k2pgctid, result_slot->tts_k2pgctid);
    } else if (slot->tts_tuple != NULL && ((HeapTuple)slot->tts_tuple)->t_k2pgctid != 0) {
      HEAPTUPLE_COPY_K2PGTID(((HeapTuple)slot->tts_tuple)->t_k2pgctid, result_slot->tts_k2pgctid);
    } else {
      elog(DEBUG1, "Could not find k2pgctid from slot");
    }
  }
 
}

#+END_SRC

#+NAME: src/gausskernel/runtime/executor/execUtils.cpp
#+BEGIN_SRC c
EState* CreateExecutorState(void) {
       /*
        * K2PG-specific fields
        */
       estate->k2pg_conflict_slot = NULL;

}
void ExecDeleteIndexTuples(TupleTableSlot* slot, ItemPointer tupleid, EState*, ...) {
  //-        index_delete(actualindex, values, isnull, tupleid);
  ItemPointer t_self = IsK2PgRelation(actualindex) ? (ItemPointer)K2PgGetPgTupleIdFromSlot(slot) : tupleid;
  index_delete(actualindex, values, isnull, t_self);
}
          */
#+END_SRC

#+NAME: src/gausskernel/runtime/executor/nodeForeignscan.cpp
#+BEGIN_SRC c
static TupleTableSlot* ForeignNext(ForeignScanState* node) {
               if (IsK2Mode()) {
                       tup->t_k2pgctid = slot->tts_k2pgctid;
               }
}
#+END_SRC

#+NAME: 
#+BEGIN_SRC c
static TupleTableSlot* IndexOnlyNext(IndexOnlyScanState* node) {
                /*
                * Fill the scan tuple slot with data from the index.  This might be
                * provided in either HeapTuple or IndexTuple format.  Conceivably an
                * index AM might fill both fields, in which case we prefer the heap
                * format, since it's probably a bit cheaper to fill a slot from.
                 */
// -        StoreIndexTuple(slot, indexScan->xs_itup, indexScan->xs_itupdesc);
               if (scandesc->xs_hitup)
               {
                       /*
                        * We don't take the trouble to verify that the provided tuple has
                        * exactly the slot's format, but it seems worth doing a quick
                        * check on the number of fields.
                        */
                       Assert(slot->tts_tupleDescriptor->natts ==
                                  scandesc->xs_hitupdesc->natts);
                       ExecStoreTuple(scandesc->xs_hitup, slot, InvalidBuffer, false);
               }
               else if (scandesc->xs_itup)
                       StoreIndexTuple(slot, scandesc->xs_itup, scandesc->xs_itupdesc);
               else
                       elog(ERROR, "no data returned for index-only scan");
 
#+END_SRC

#+NAME: src/gausskernel/runtime/executor/nodeModifyTable.cpp
#+BEGIN_SRC c
static Oid ExecUpsert(ModifyTableState* state, TupleTableSlot* slot, ..) {
                       if (!IsK2PgRelation(resultRelationDesc)) {
                               // K2PG does not use Postgres transaction control code.
                 ExecCheckTIDVisible(targetrel, estate, targetrel, &conflictInfo.conflictTid);
            }
}

static Oid ExecUpsert(ModifyTableState* state, TupleTableSlot* slot, ...) {
       if (IsK2PgRelation(resultRelationDesc))
       {
        newid = K2PgHeapInsert(slot, (HeapTuple)tuple, estate);
        /* insert index entries for tuple */
               if (K2PgRelInfoHasSecondaryIndices(resultRelInfo)) {
            ItemPointer item = (ItemPointer)DatumGetPointer(((HeapTuple)tuple)->t_k2pgctid);
            recheckIndexes = ExecInsertIndexTuples(slot, item, estate, heaprel, partition, bucketid, &specConflict, NULL);
        }
       }
}

TupleTableSlot* ExecInsertT(ModifyTableState* state, TupleTableSlot* slot, TupleTableSlot* planSlot, EState* estate,
     bool canSetTag, int options, List** partitionList) {
       /*
        * The attribute "k2pg_conflict_slot" is only used within ExecInsert.
        * Initialize its value to NULL.
        */
       estate->k2pg_conflict_slot = NULL;
                if (IsK2PgRelation(result_relation_desc)) {
                    pTSelf = (ItemPointer)DatumGetPointer(K2PgGetPgTupleIdFromSlot(slot));


if (IsK2PgRelation(result_relation_desc))
       {
               bool row_found = K2PgExecuteDelete(result_relation_desc, planSlot, estate, node);
               if (!row_found)
               {
                       /*
                        * No row was found. This is possible if it's a single row txn
                        * and there is no row to delete (since we do not first do a scan).
                        */
                       return NULL;
               }

               if (K2PgRelInfoHasSecondaryIndices(result_rel_info))
               {
                       /* Delete index entries of the old tuple
            *
            */
            ItemPointer k2pg_ctid = (ItemPointer)DatumGetPointer(K2PgGetPgTupleIdFromSlot(planSlot));
                       ExecDeleteIndexTuples(planSlot, k2pg_ctid, estate, part_relation, partition, NULL, false);
               }
}
 if (IsK2PgRelation(result_relation_desc)) {
                if (node->k2pg_mt_is_single_row_update_or_delete)
                {
                    slot = planSlot;
                }
                else
                {
                    slot = ExecFilterJunk(result_rel_info->ri_junkFilter, planSlot);
                }

if (IsK2PgRelation(result_relation_desc)) {
        // TODO: double check the logic here

               /*
                * Check the constraints of the tuple.
                */
        if (result_relation_desc->rd_att->constr) {
            if (node->mt_insert_constr_slot == NULL) {
                ExecConstraints(result_rel_info, slot, estate);
            } else {
                ExecConstraints(result_rel_info, node->mt_insert_constr_slot, estate);
            }
        }

               RangeTblEntry *rte = rt_fetch(result_rel_info->ri_RangeTableIndex,
                                                                         estate->es_range_table);

ols);

               if (!row_found)
               {
                       /*
                        * No row was found. This is possible if it's a single row txn
                        * and there is no row to update (since we do not first do a scan).
                        */
                       return NULL;
               }

               /*
                * Update indexes if needed.
                */
               if (K2PgRelInfoHasSecondaryIndices(result_rel_info))
               {
            ItemPointer item = (ItemPointer)DatumGetPointer(((HeapTuple)tuple)->t_k2pgctid);
                       /* Delete index entries of the old tuple */
            ExecDeleteIndexTuples(slot, item, estate, fake_part_rel, partition, NULL, false);

                       /* Insert new index entries for tuple */
            List* recheckIndexes = ExecInsertIndexTuples(slot, item, estate, fake_part_rel, partition, bucketid, NULL, NULL);
               }
                                ItemPointer item;
                                if (IsK2PgRelation(fake_insert_relation))
                                {
                                    item = (ItemPointer)DatumGetPointer(((HeapTuple)tuple)->t_k2pgctid);
                                } else {
                                    item = &(((HeapTuple)tuple)->t_self);
                                }

               /*
                * Prepare the updated tuple in inner slot for RETURNING clause execution.
                * For ON CONFLICT DO UPDATE, the INSERT returning clause is setup
                * differently, so junkFilter is not needed.
                */
               if (IsK2PgRelation(result_relation_desc) && result_rel_info->ri_junkFilter)
                       slot = ExecFilterJunk(result_rel_info->ri_junkFilter, planSlot);


}

TupleTableSlot* ExecModifyTable(ModifyTableState* node) {

                               /*
                                * For K2PG relations extract the old row from the wholerow junk
                                * attribute if needed.
                                * 1. For tables with secondary indexes we need the (old) k2pgctid for
                                *    removing old index entries (for UPDATE and DELETE)
                                * 2. For tables with row triggers we need to pass the old row for
                                *    trigger execution.
                                */
                               if (IsK2PgRelation(result_rel_info->ri_RelationDesc) &&
                                       (K2PgRelInfoHasSecondaryIndices(result_rel_info) ||
                                       K2PgRelHasOldRowTriggers(result_rel_info->ri_RelationDesc,
                                                              operation)))
                               {
                               resno = ExecFindJunkAttribute(junk_filter, "wholerow");
                                       datum = ExecGetJunkAttribute(slot, resno, &isNull);

                                       /* shouldn't ever get a null result... */
                                       if (isNull)
                                               elog(ERROR, "wholerow is NULL");

                    old_tuple = DatumGetHeapTupleHeader(datum);
                                       resno = ExecFindJunkAttribute(junk_filter, "k2pgctid");
                                       datum = ExecGetJunkAttribute(slot, resno, &isNull);

                                       /* shouldn't ever get a null result... */
                                       if (isNull)
                                               elog(ERROR, "k2pgctid is NULL");

                                       // old_tuple->t_k2pgctid = datum;

                                       // // oldtuple = &oldtupdata;
                    tuple_id = (ItemPointer)DatumGetPointer(datum);
                    tuple_ctid = *tuple_id; /* be sure we don't free ctid!! */
                    tuple_id = &tuple_ctid;

}
ModifyTableState* ExecInitModifyTable(ModifyTable* node, EState* estate, ...) {
 mt_state->k2pg_mt_is_single_row_update_or_delete = K2PgIsSingleRowUpdateOrDelete(node);
 //               junk_filter_needed = true;
                               /*
                                * If it's a K2PG single row UPDATE/DELETE we do not perform an
                                * initial scan to populate the k2pgctid, so there is no junk
                                * attribute to extract.
                                */
                               junk_filter_needed = !mt_state->k2pg_mt_is_single_row_update_or_delete;
                 break;
                    if (IsK2PgRelation(result_rel_info->ri_RelationDesc))
                                       {
                                               j->jf_junkAttNo = ExecFindJunkAttribute(j, "k2pgctid");
                                               if (!AttributeNumberIsValid(j->jf_junkAttNo)) {
                                                       elog(ERROR, "could not find junk k2pgctid column");
                                               }
                                       }
                    else if (relkind == RELKIND_RELATION) {
                         j->jf_junkAtt
}

#+END_SRC

#+NAME: rc/gausskernel/storage/access/common/heaptuple.cpp
#+BEGIN_SRC c
 bool heap_attisnull(HeapTuple tup, int attnum, TupleDesc tupDesc) {
+       case K2PgTupleIdAttributeNumber:
+           /* If selected, virtual K2PG columns are never null */
+           break;
}
 Datum heap_getsysattr(HeapTuple tup, int attnum, TupleDesc tupleDesc, ) {
+               case K2PgTupleIdAttributeNumber:
+                       result = tup->t_k2pgctid;
+                       break;
}
HeapTuple heap_copytuple(HeapTuple tuple) {
+    HEAPTUPLE_COPY_K2PGTID(tuple->t_k2pgctid, newTuple->t_k2pgctid);
}
void heap_copytuple_with_tuple(HeapTuple src, HeapTuple dest) {
HEAPTUPLE_COPY_K2PGTID(src->t_k2pgctid, dest->t_k2pgctid);
}
HeapTuple heap_form_tuple(TupleDesc tupleDescriptor, Datum *values, bool *isnull) {
   tuple->t_k2pgctid = 0;
}
HeapTuple heap_form_tuple(TupleDesc tupleDescriptor, Datum *values, bool *isnull, ...) {
    /* We also make sure that t_ctid is invalid unless explicitly set */
+    ItemPointerSetInvalid(&(td->t_ctid));
 
}
HeapTuple heap_modify_tuple(HeapTuple tuple, TupleDesc tupleDesc, Datum *replVal) {
HEAPTUPLE_COPY_K2PGTID(tuple->t_k2pgctid, newTuple->t_k2pgctid);
}
 HeapTuple heap_tuple_from_minimal_tuple(MinimalTuple mtup) {
result->t_k2pgctid = 0;
}

HeapTuple heap_slot_copy_heap_tuple(TupleTableSlot *slot) {
+    HeapTuple tup = heap_form_tuple(slot->tts_tupleDescriptor, slot->tts_values, slot->tts_isnull);
+    if (slot->tts_k2pgctid != 0) {
+        HEAPTUPLE_COPY_K2PGTID(slot->tts_k2pgctid, tup->t_k2pgctid);
+    } else if (slot->tts_tuple != NULL && ((HeapTuple)slot->tts_tuple)->t_k2pgctid != 0) {
+        HEAPTUPLE_COPY_K2PGTID(((HeapTuple)slot->tts_tuple)->t_k2pgctid, tup->t_k2pgctid);
+    }
+    return tup;
}
#+END_SRC

#+NAME: src/gausskernel/storage/access/heap/heapam.cpp
#+BEGIN_SRC c
static void initscan(HeapScanDesc scan, ScanKey key, bool is_rescan) {
scan->rs_ctup.t_k2pgctid = (Datum) 0;
// Skip RelationIsBucket(relation)
}
static HeapScanDesc heap_beginscan_internal(Relation relation, Snapshot snapshot, ...) {
+       /* K2PG scan methods should only be used for tables that are handled by K2 PgGate. */
+       if (IsK2PgRelation(relation))
+       {
+        // TODO: check to see if we need to set and pass in bool temp_snap
+               return cam_heap_beginscan(relation, snapshot, nkeys, key, false);
+       }
+
}

void heap_endscan(TableScanDesc sscan) {
+
+       if (IsK2PgRelation(scan->rs_base.rs_rd))
+       {
+               return cam_heap_endscan(scan);
+       }
+
}
void heap_endscan(TableScanDesc sscan) {
+
+       if (IsK2PgRelation(scan->rs_base.rs_rd))
+       {
+               return cam_heap_endscan(scan);
+       }
+
}
HeapTuple heap_getnext(TableScanDesc sscan, ScanDirection direction) {
+
+       if (IsK2PgRelation(scan->rs_base.rs_rd))
+       {
+               return cam_heap_getnext(scan);
+       }
+
}
Oid heap_insert(Relation relation, HeapTuple tup, CommandId cid, int options, ...) {
 +    if (IsK2PgRelation(relation)) {
+        return K2PgExecuteInsert(relation, RelationGetDescr(relation), tup);
+    }
}
int heap_multi_insert(Relation relation, Relation parent, HeapTuple* tuples, ...) {
+    if (IsK2PgRelation(relation))
+    {
+           ereport(ERROR,
+                   (errcode(ERRCODE_INTERNAL_ERROR),
+                           errmsg("Operation not allowed in K2PG mode")));
+    }
+
}

TM_Result heap_delete(Relation relation, ItemPointer tid, CommandId cid,...) {
+    if (IsK2PgRelation(relation)) {
+        ereport(ERROR, (errcode(ERRCODE_INVALID_OPERATION), errmsg("Invalid call on heap_delete for k2 relation %d", relation->_i
d)));
}

void simple_heap_delete(Relation relation, ItemPointer tid, int options, ...) {
void simple_heap_delete(Relation relation, ItemPointer tid, int options, bool al
     TM_Result result;
     TM_FailureData tmfd;
 
+    if (IsK2PgRelation(relation)) {
+        ereport(ERROR, (errcode(ERRCODE_INVALID_OPERATION), errmsg("Invalid call on simple_heap_delete for k2 relation %d", relio
n->rd_id)));                                                                                                                     
+    }
}

void simple_heap_update(Relation relation, ItemPointer otid, HeapTuple tup)
+{
+    if (IsK2PgRelation(relation)) {
+        K2PgUpdateSysCatalogTuple(relation, NULL, tup);
+    } else {
+        simple_heap_update_internal(relation, otid, tup);
+    }
+}
+void simple_heap_update_internal(Relation relation, ItemPointer otid, HeapTuple tup) {
+    /*
+        * This will only be used for non-K2PG tuples (e.g. Temp tables) so we just
+        * need to set the k2pgctid to 0 (NULL) here.
+        */
+       tuple->t_k2pgctid = (Datum) 0;
+
}

void heap_inplace_update(Relation relation, HeapTuple tuple) {
       if (IsK2PgEnabled())
+       {
+               K2PgUpdateSysCatalogTuple(relation, NULL /* oldtuple */, tuple);
+               return;
+       }
+
}
#+END_SRC

#+NAME: src/gausskernel/storage/access/index/genam.cpp
#+BEGIN_SRC c
RelationGetIndexScan(Relation index_relation, int nkeys, int norde, ...) {
+       scan->xs_hitup = NULL;
+       scan->xs_hitupdesc = NULL;
}

SysScanDesc systable_beginscan(Relation heap_relation, Oid index_id, bool, ) {
+       if (IsK2PgEnabled())
+       {
+               return cam_systable_beginscan(heap_relation,
+                                             index_id,
+                                             index_ok,
+                                             snapshot,
+                                             nkeys,
+                                             key);
+       }

}

HeapTuple systable_getnext(SysScanDesc sysscan) {
+       if (IsK2PgEnabled())
+       {
+               return cam_systable_getnext(sysscan);
+       }
}

bool systable_recheck_tuple(SysScanDesc sysscan, HeapTuple tup) {
+    if (sysscan->k2scan) {
+        return true;
+    }
}

HeapTuple systable_getnext_back(SysScanDesc sysscan) {
       if (sysscan->scan != NULL) {
             htup = heap_getnext((TableScanDesc) (sysscan->scan), BackwardScanDirection);
+        } else {
+            if (IsK2PgEnabled()) {
+                htup = cam_systable_getnext(sysscan);
+            } else {
+                ereport(ERROR, (errmsg("HeapScan in SysScanDesc is null")));
+            }
+        }
}
#+END_SRC

#+NAME: src/gausskernel/storage/access/index/indexam.cpp
#+BEGIN_SRC c
void index_close(Relation relation, LOCKMODE lockmode) {
  // Skip bucket close for k2pg
}

void index_delete(Relation index_relation, Datum* values, const bool* isnull, ItemPointer heap_t_ctid) {
+    if (IsK2PgRelation(index_relation)) {
+        Datum k2pgctid = PointerGetDatum(heap_t_ctid);
+               K2PgExecuteDeleteIndex(index_relation, values, isnull, k2pgctid);
+    } 
}

Tuple IndexFetchTuple(IndexScanDesc scan) {
+       /*
+        * For K2PG secondary indexes, there are two scenarios.
+        * - If K2PG returns an index-tuple, the returned k2pgctid value should be used to query data.
+        * - If K2PG returns a heap_tuple, all requested data was already selected in the tuple.
+        */
+       if (IsK2PgEnabled())
+       {
+               if (scan->xs_hitup != 0)
+                       return scan->xs_hitup;
+               return CamFetchTuple(scan->heapRelation, scan->xs_ctup.t_k2pgctid);
+       }
+
}
#+END_SRC

#+NAME: src/gausskernel/storage/access/table/tableam.cpp
#+BEGIN_SRC c
List *HeapamTopsExecUpdateIndexTuples(TupleTableSlot *slot, TupleTableSlot *olds, ...) {
  // why tupleid is not used here?
+    ItemPointer item;
+    if (IsK2PgRelation(relation))
+    {
+        item = (ItemPointer)DatumGetPointer(((HeapTuple)tuple)->t_k2pgctid);
+    } else {
+        item = &(((HeapTuple)tuple)->t_self);
+    }
+    recheckIndexes = ExecInsertIndexTuples(slot, item, exec_index_tuples_state.estate,
}
#+END_SRC


#+NAME: src/gausskernel/storage/access/transam/varsup.cpp
#+BEGIN_SRC c
+/*
+ * Number of OIDs to prefetch (preallocate) in K2PG setup.
+ * Given there are multiple Postgres nodes, each node should prefetch
+ * in smaller chunks.
+ */
+#define K2PG_OID_PREFETCH              256
+
Oid GetNewObjectId(bool IsToastRel) {
+               if (IsK2PgEnabled())
+               {
+                       Oid begin_oid = InvalidOid;
+                       Oid end_oid   = InvalidOid;
+
+            K2PgReservePgOids(u_sess->proc_cxt.MyDatabaseId,
+                        t_thrd.xact_cxt.ShmemVariableCache->nextOid,
+                                   K2PG_OID_PREFETCH,
+                                   &begin_oid,
+                                   &end_oid);
+
+            t_thrd.xact_cxt.ShmemVariableCache->nextOid = begin_oid;
+                       t_thrd.xact_cxt.ShmemVariableCache->oidCount = end_oid - begin_oid;
+               }
}
#+END_SRC

#+NAME: src/gausskernel/storage/access/transam/xact.cpp
#+BEGIN_SRC c
static TransactionId RecordTransactionCommit(void) {
+       if (IsK2PgEnabled())
+       {
+               return latestXid;
+       }

}

static void PrepareTransaction(bool STP_commit) {
+    if (!IsK2PgEnabled()) {
         PostPrepare_Locks(xid);
         PostPrepare_PredicateLocks(xid);
+    }

static void AbortTransaction(bool PerfectRollback, bool STP_rollback) {
    if (!IsK2PgEnabled()) {
         LockErrorCleanup();
+    }

}
}
#+END_SRC

#+NAME: src/gausskernel/storage/buffer/bufmgr.cpp
#+BEGIN_SRC c
BlockNumber RelationGetNumberOfBlocksInFork(Relation relation, ForkNumber fork_num, bool estimate) {
+
+    if (IsK2PgBackedRelation(relation)) {
+        return result;
+    }
}
#+END_SRC

#+NAME: src/gausskernel/storage/ipc/ipc.cpp
#+BEGIN_SRC c
void proc_exit(int code) {
+       if (IsK2PgEnabled())
+               K2PgOnPostgresBackendShutdown();
+
}
#+END_SRC

#+NAME: src/gausskernel/storage/mot/fdw_adapter/mot_fdw.cpp
#+BEGIN_SRC c
Datum mot_fdw_handler(PG_FUNCTION_ARGS) {
-    fdwroutine->AnalyzeForeignTable = MOTAnalyzeForeignTable;
-    fdwroutine->AcquireSampleRows = MOTAcquireSampleRowsFunc;
+    fdwroutine->AnalyzeForeignTable = NULL;
+    fdwroutine->AcquireSampleRows = NULL;
 
}
static void MOTEndForeignScan(ForeignScanState* node) {
// comment
}
#+END_SRC

#+NAME: src/include/access/htup.h
#+BEGIN_SRC c
typedef struct HeapTupleData {
Datum              t_k2pgctid;             /* virtual column k2pgctid */
}
#+END_SRC

#+NAME: src/include/access/itup.h
#+BEGIN_SRC c
 typedef struct IndexTupleData {
+       Datum                   t_k2pgctid;     /* virtual column k2pgctid */
 }

+/* Copy k2pgctid from a source tuple to a new / destination tuple */
+
+#define HEAPTUPLE_COPY_K2PGTID(src, dest)                            \
+    do {                                                            \
+            dest = (src == 0) ? 0 :                                 \
+                PointerGetDatum(cstring_to_text_with_len(VARDATA_ANY(src), \
+                                                         VARSIZE_ANY_EXHDR(src))); \
+    } while (false)
 
#+END_SRC

#+NAME: src/include/access/relscan.h
#+BEGIN_SRC c
typedef struct HeapScanDescData {
bool rs_temp_snap;      /* unregister snapshot at scan end? */
}

typedef struct HeapScanDescData {
CamScanDesc        k2scan;                 /* only valid in k2-scan case */
}

typedef struct IndexScanDescData {
+       HeapTuple       xs_hitup;               /* index data returned by AM, as HeapTuple */
+       TupleDesc       xs_hitupdesc;   /* rowtype descriptor of xs_hitup */
+
+       /* During execution, Postgres will push down hints to K2PG for performance purpose.
+        * (currently, only LIMIT values are being pushed down). All these execution information will
+        * kept in "k2pg_exec_params".
+        *
+        * - Generally, "k2pg_exec_params" is kept in execution-state. As Postgres executor traverses and
+        *   excutes the nodes, it passes along the execution state. Necessary information (such as
+        *   LIMIT values) will be collected and written to "k2pg_exec_params" in EState.
+        *
+        * - However, IndexScan execution doesn't use Postgres's node execution infrastructure. Neither
+        *   execution plan nor execution state is passed to IndexScan operators. As a result,
+        *   "k2pg_exec_params" is kept in "IndexScanDescData" to avoid passing EState to a lot of
+        *   IndexScan functions.
+        *
+        * - Postgres IndexScan function will call and pass "k2pg_exec_params" to PgGate to control the
+        *   index-scan execution in K2PG.
+        */
+       K2PgSelectLimitParams k2pg_exec_params;
+
 
}

typedef struct SysScanDescData {
+       Snapshot        snapshot;               /* snapshot to unregister at end of scan */
+    CamScanDesc        k2scan;                 /* only valid in k2-scan case */

}
#+END_SRC

#+NAME: src/include/access/sysattr.h
#+BEGIN_SRC c
+#define FirstLowInvalidHeapAttributeNumber (-8)
+#define K2PgTupleIdAttributeNumber                             (-8)
+#define K2PgFirstLowInvalidAttributeNumber             (-9)

+/*
+ * RowId is an auto-generated K2 record column used for tables without a
+ * primary key, but is not present in the postgres table.
+ *
+ * It is included here to reserve the number and for use in K2PG postgres
+ * code that requires knowledge about this column.
+ */
+#define K2PgRowIdAttributeNumber                                       (-100)
 
+#define K2PgIdxBaseTupleIdAttributeNumber                      (-101)
+#define K2PgUniqueIdxKeySuffixAttributeNumber          (-102)
+#define K2PgSystemFirstLowInvalidAttributeNumber       (-103)
 
#+END_SRC

#+NAME: src/include/catalog/pg_am.h
#+BEGIN_SRC c
2invacuumcleanup k2incanreturn k2incostestimate k2inoptions));
+DESCR("k2 b-tree index access method");
+#define K2INDEX_AM_OID 10030
+
#+END_SRC

#+NAME: src/include/catalog/pg_index.h
#+BEGIN_SRC c
+/* Options for K2PG-based index */
+#define INDOPTION_HASH                 0x0004  /* values are hash-indexed */
+
#+END_SRC

#+NAME: src/include/catalog/pg_opclass.h
#+BEGIN_SRC c
+/* k2index index to make index work */
+DATA(insert ( 10030    int4_ops         PGNSP    PGUID  10050    23    t    0));
+DATA(insert ( 10030    int2_ops         PGNSP    PGUID  10050    21    t    0));
+DATA(insert ( 10030    int8_ops         PGNSP    PGUID  10050    20    t    0));
+DATA(insert ( 10030    oid_ops          PGNSP    PGUID  10051    26    t    0));
+DATA(insert ( 10030    date_ops         PGNSP    PGUID  10052  1082    t    0));
+DATA(insert ( 10030    timestamp_ops    PGNSP    PGUID  10052  1114    t    0));
+DATA(insert ( 10030    timestamptz_ops  PGNSP    PGUID  10052  1184    t    0));
+DATA(insert ( 10030    float4_ops       PGNSP    PGUID  10053   700    t    0));
+DATA(insert ( 10030    float8_ops       PGNSP    PGUID  10053   701    t    0));
+DATA(insert ( 10030    numeric_ops      PGNSP    PGUID  10054  1700    t    0));
+DATA(insert ( 10030    text_ops         PGNSP    PGUID  10055    25    t    0));
+DATA(insert ( 10030    bpchar_ops       PGNSP    PGUID  10056  1042    t    0));
+DATA(insert ( 10030    time_ops         PGNSP    PGUID  10057  1083    t    0));
+DATA(insert ( 10030    timetz_ops       PGNSP    PGUID  10058  1266    t    0));
+DATA(insert ( 10030    money_ops        PGNSP    PGUID  10059   790    t    0));
+DATA(insert ( 10030    interval_ops     PGNSP    PGUID  10060  1186    t    0));
+DATA(insert ( 10030    tinterval_ops    PGNSP    PGUID  10061   704    t    0));
+DATA(insert ( 10030    int1_ops         PGNSP    PGUID  10062  5545    t    0));
+DATA(insert ( 10030    bool_ops         PGNSP    PGUID  10063    16    t    0));
+DATA(insert ( 10030    smalldatetime_ops  PGNSP  PGUID  10064  9003    t    0));
+DATA(insert ( 10030    name_ops         PGNSP    PGUID  10065   19     t    0));
+DATA(insert ( 10030    char_ops         PGNSP    PGUID  10066   18     t    0));
+DATA(insert ( 10030    array_ops        PGNSP    PGUID  10067   2277   t    0));
+DATA(insert ( 10030    bit_ops          PGNSP    PGUID  10068   1560   t    0));
+DATA(insert ( 10030    bytea_ops        PGNSP    PGUID  10069   17     t    0));
+DATA(insert ( 10030    abstime_ops      PGNSP    PGUID  10070   702    t    0));
+DATA(insert ( 10030    oidvector_ops    PGNSP    PGUID  10072   30     t    0));
+DATA(insert ( 10030    record_ops       PGNSP    PGUID  10073   2249   t    0));
+DATA(insert ( 10030    varbit_ops       PGNSP    PGUID  10074   1562   t    0));
+DATA(insert ( 10030    tid_ops          PGNSP    PGUID  10075   27     t    0));
+DATA(insert ( 10030    xid_ops          PGNSP    PGUID  10076   28     t    0));
+DATA(insert ( 10030    cid_ops          PGNSP    PGUID  10077   29     t    0));
+DATA(insert ( 10030    macaddr_ops      PGNSP    PGUID  10078   829    t    0));

#+END_SRC

#+NAME: src/include/catalog/pg_opfamily.h b/src/include/catalog/pg_opfamily.h
#+BEGIN_SRC c
+// k2index op family to make index work
+DATA(insert OID = 10050 (10030    integer_ops      PGNSP    PGUID));
+DATA(insert OID = 10051 (10030    oid_ops          PGNSP    PGUID));
+DATA(insert OID = 10052 (10030    datetime_ops     PGNSP    PGUID));
+DATA(insert OID = 10053 (10030    float_ops        PGNSP    PGUID));
+DATA(insert OID = 10054 (10030    numeric_ops      PGNSP    PGUID));
+DATA(insert OID = 10055 (10030    text_ops         PGNSP    PGUID));
+DATA(insert OID = 10056 (10030    bpchar_ops       PGNSP    PGUID));
+DATA(insert OID = 10057 (10030    time_ops         PGNSP    PGUID));
+DATA(insert OID = 10058 (10030    timetz_ops       PGNSP    PGUID));
+DATA(insert OID = 10059 (10030    money_ops        PGNSP    PGUID));
+DATA(insert OID = 10060 (10030    interval_ops     PGNSP    PGUID));
+DATA(insert OID = 10061 (10030    tinterval_ops    PGNSP    PGUID));
+DATA(insert OID = 10062 (10030    int1_ops         PGNSP    PGUID));
+DATA(insert OID = 10063 (10030    bool_ops         PGNSP    PGUID));
+DATA(insert OID = 10064 (10030    smalldatetime_ops  PGNSP  PGUID));
+DATA(insert OID = 10065 (10030    name_ops         PGNSP    PGUID));
+DATA(insert OID = 10066 (10030    char_ops         PGNSP    PGUID));
+DATA(insert OID = 10067 (10030    array_ops        PGNSP    PGUID));
+DATA(insert OID = 10068 (10030    bit_ops          PGNSP    PGUID));
+DATA(insert OID = 10069 (10030    bytea_ops        PGNSP    PGUID));
+DATA(insert OID = 10070 (10030    abstime_ops      PGNSP    PGUID));
+DATA(insert OID = 10071 (10030    network_ops      PGNSP    PGUID));
+DATA(insert OID = 10072 (10030    oidvector_ops    PGNSP    PGUID));
+DATA(insert OID = 10073 (10030    record_ops       PGNSP    PGUID));
+DATA(insert OID = 10074 (10030    varbit_ops       PGNSP    PGUID));
+DATA(insert OID = 10075 (10030    tid_ops          PGNSP    PGUID));
+DATA(insert OID = 10076 (10030    xid_ops          PGNSP    PGUID));
+DATA(insert OID = 10077 (10030    cid_ops          PGNSP    PGUID));
+DATA(insert OID = 10078 (10030    macaddr_ops      PGNSP    PGUID));
#+END_SRC

#+NAME: /src/include/executor/tuptable.h
#+BEGIN_SRC c
typedef struct TupleTableSlot {
+       /* K2PG support */
+       Datum tts_k2pgctid; /* selected k2pgctid value */
}

#+END_SRC

#+NAME: src/include/knl/knl_instance.h
#+BEGIN_SRC c
+typedef struct knl_g_k2_context {
+    bool isK2ModelEnabled;
+} knl_g_k2_context;

typedef struct knl_instance_context {
 knl_g_k2_context k2_cxt;
}
#+END_SRC


#+NAME: src/include/miscadmin.h
#+BEGIN_SRC c
#define IsK2Mode() (g_instance.k2_cxt.isK2ModelEnabled)
#+END_SRC

#+NAME: src/include/nodes/execnodes.h
#+BEGIN_SRC c
typedef struct EState {
typedef struct EState {
 #endif
 
     PruningResult* pruningResult;
+
+       /*
+        * K2PG-specific fields
+        */
+    // TODO: add conflict handling logic for conflict tuples
+       TupleTableSlot *k2pg_conflict_slot; /* If a conflict is to be resolved when inserting data,
rocessing and
s resolved. */
}

typedef struct ModifyTableState {
+       /* K2PG specific attributes. */
+       bool k2pg_mt_is_single_row_update_or_delete;
}
#+END_SRC

#+NAME: src/include/nodes/memnodes.h
#+BEGIN_SRC c
typedef struct MemoryContextData {
K2PgMemctx k2pg_memctx;        /* Memory context for objects in k2 */
}
#+END_SRC

#+NAME: src/include/nodes/parsenodes_common.h
#+BEGIN_SRC c
typedef struct Constraint {
+       /* For K2PG LSM primary or unique key defined inline with the table
+        * definition, we allow the key definition to include the sorting info
+        * like "create table (... primary key (h hash, r1 asc, r2 desc))".
+        * We save the IndexElem of the attributes in 'k2pg_index_params' to access
+        * the full definition of the key attributes.
+        */
+       List       *k2pg_index_params;  /* IndexElem nodes of UNIQUE or PRIMARY KEY
+                                                                        * constraint */
}
#+END_SRC

#+NAME: src/include/nodes/plannodes.h
#+BEGIN_SRC c
typedef struct ModifyTable {
      List       *k2PushdownTlist; /* tlist for the pushed down SET expressions */

}
#+END_SRC

#+NAME: src/include/utils/be_module.h
#+BEGIN_SRC c
enum ModuleId {
MOD_K2,           /* K2 */
}
#+END_SRC

#+NAME: src/include/utils/palloc.h
#+BEGIN_SRC c
/*
+ * This enables running query-layer code in a multi-threaded constext by using
+ * thread-local variables instead of globals.
+ * Currently only used for expression evaluation in K2 PG (i.e. for pushdown).
+ */
+static inline bool IsMultiThreadedMode() {
+       /*
+        * Just checking if the memory infrastructure is initialized.
+        * TODO Consider using a specific global variable or compiler flag
+        * for this.
+        */
+       return CurrentMemoryContext == NULL;
+}
+
+extern MemoryContext GetThreadLocalCurrentMemoryContext();
+extern MemoryContext SetThreadLocalCurrentMemoryContext(MemoryContext memctx);
+
+static inline MemoryContext GetCurrentMemoryContext() {
+       if (IsMultiThreadedMode())
+       {
+               return (MemoryContext) GetThreadLocalCurrentMemoryContext();
+       }
+       else
+       {
+               return CurrentMemoryContext;
+       }
+}
+
#+END_SRC

#+NAME: src/include/utils/rel.h
#+BEGIN_SRC c
typedef struct RelationData {
 Oid        rd_pkindex;             /* OID of primary key, if any */
}

#+END_SRC

#+NAME: src/include/utils/selfuncs.h
#+BEGIN_SRC c
+
+/*
+ * deconstruct_indexquals is a simple function to examine the indexquals
+ * attached to a proposed IndexPath.  It returns a list of IndexQualInfo
+ * structs, one per qual expression.
+ */
+typedef struct
+{
+       RestrictInfo *rinfo;            /* the indexqual itself */
+       int                     indexcol;               /* zero-based index column number */
+       bool            varonleft;              /* true if index column is on left of qual */
+       Oid                     clause_op;              /* qual's operator OID, if relevant */
+       Node       *other_operand;      /* non-index operand of qual's operator */
+} IndexQualInfo;
+
#+END_SRC
